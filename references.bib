%0 Web Page
%T 李飞飞团队“50美元”复刻DeepSeek，一文读透背后逻辑 - 中国知网
%U https://kns.cnki.net/kcms2/article/abstract?v=Zw74qSZOFgiFm0BNh7zBxXAztEOHyFDVRjmb-Kl1wwnDdrp2N2up_J3VNplMg8gVZR_ei9B7f8ZM1_JXRj8x51joaO8H8sl24TNcBzNMbaewCSFVmgRyAj5aO-Hdj4nhgjwMG8cGjwghJFzdkioYXEifgAGb5QyS_3XqWyOEoxzUQa3FvwaLUiYxpJLMgtNd&uniplatform=NZKPT&language=CHS

%0 Journal Article
%T Reconfigurable modular acoustic metamaterial for broadband sound absorption
%V 226
%P 112348
%U https://linkinghub.elsevier.com/retrieve/pii/S0888327025000494
%X This study presents a reconfigurable acoustic metamaterial consisting of stacked multiple absorption modules, which can achieve efficient broadband sound absorption in both enclosed space and ventilation system. Each absorption module is composed of four Helmholtz resonators with embedded tubes, forming a square-shape structure with an air channel in the middle of the module. A theoretical model based on the impedance transfer method and a simulation model based on the finite element method were developed to investigate the sound absorption performance and the underlying working mechanisms of the metamaterial. Through the coupled resonance effects, each module exhibits a wide operating frequency band, and the absorption frequency range can be adjusted by modifying the module’s geometrical parameters. And by stacking multiple modules, the acoustic metamaterial achieves an absorption performance that covers the operating frequency range of each module. Additionally, it was found that the interlayer coupling effects of modules significantly enhance overall absorption performance due to stepped well design in the center of the metamaterial. Moreover, by reconfigure the absorption modules, the acoustic metamaterial can be easily customized to achieve the desired absorption spectra. To illustrate the design concept, a metamaterial consisted of five-layer absorption modular is presented, with an average absorption coefficient of 0.92 within 450–2000 Hz range. Furthermore, the proposed metamaterial can be applied in different scenarios, i.e., with open and cloesed end. In the case where a rigid backing is placed at the bottom, the metamaterial can be applied as a sound absorber and its absorption bandwidth can be broadened to 430–2600 Hz by incorporating a porous material liner within the stepped well. In another case where the bottom of the stepped well is left open, the metamaterial can be used as a ventilation barrier, allowing airflow circulation and suppressing up to 90 % of sound energy within the 650–2400 Hz range. Therefore, not only does the proposed acoustics metamaterial design realize structural reconfigurability, but it also suggests a robust solution to low frequency noise-control that caters to diverse noise reduction requirements.
%G en
%J Mechanical Systems and Signal Processing
%A Mei, Zhongjian
%A Shi, Tongyang
%A Lyu, Yadong
%A Li, Xiaodong
%A Cheng, Xiaobin
%A Yang, Jun
%D 03/2025

%0 Journal Article
%T Design of flexural bottle beam metasurface with resonant pillar-type metamaterials
%V 99
%N 12
%P 125950
%U https://iopscience.iop.org/article/10.1088/1402-4896/ad8f04
%X In this paper, we design a ﬂexural metasurface capable of transforming plane or cylindrical waves into bottle shaped beam. The refractive index of the metasurface is calculated by Generalized Snell’s Law and discretized into 5 × 201 lattices, which is ﬁnally realized by resonant pillar-type unit cells. Simulation results demonstrate the bottle shaped focusing effect of the metasurface, which remains robust even in the presence of a scatterer inside the bottle beam. This work provides a theoretical and simulation foundation for the application and experiment of bottle beam in ﬂexural wave control.
%G en
%J Physica Scripta
%A Wu, Yunhao
%A Sun, Zhaoyong
%A Tian, Yimin
%A Yang, Jun
%D 2024-12-01

%0 Journal Article
%T Design of flexural wave bessel metasurface with resonant pillar-type metamaterials
%V 99
%N 5
%P 055927
%U https://iopscience.iop.org/article/10.1088/1402-4896/ad3863
%X In this paper, we design a ﬂexural wave Bessel metasurface with resonant pillars, which converts the ﬂexural wave produced by a point into a Bessel beam. The refractive index is determined through the application of the generalized Snell’s law, subsequently discretized into pixel blocks. These blocks facilitate implementation via the use of metamaterial unit cells. The metasurface is realized by resonant pillar-type metamaterials, and composed of 41 different independent unit cells obtained by retrieving the energy bands. Simulation results demonstrate that the designed metasurface exhibits effective focusing for ﬂexural wave. Additionally, the self-reconstruction effect of the Bessel metasurface is veriﬁed through the introduction of obstacles. This research provides a new perspective for the application of Bessel beam in the domain of ﬂexural wave.
%G en
%J Physica Scripta
%A Liu, Yining
%A Dou, Shuihai
%A Du, Yanping
%A Zhao, Liuxian
%A Sun, Zhaoyong
%D 2024-05-01

%0 Generic
%T s1: Simple test-time scaling
%I arXiv
%U http://arxiv.org/abs/2501.19393
%X Test-time scaling is a promising new approach to language modeling that uses extra test-time compute to improve performance. Recently, OpenAI’s o1 model showed this capability but did not publicly share its methodology, leading to many replication efforts. We seek the simplest approach to achieve test-time scaling and strong reasoning performance. First, we curate a small dataset s1K of 1,000 questions paired with reasoning traces relying on three criteria we validate through ablations: difficulty, diversity, and quality. Second, we develop budget forcing to control test-time compute by forcefully terminating the model’s thinking process or lengthening it by appending “Wait” multiple times to the model’s generation when it tries to end. This can lead the model to doublecheck its answer, often fixing incorrect reasoning steps. After supervised finetuning the Qwen2.532B-Instruct language model on s1K and equipping it with budget forcing, our model s1-32B exceeds o1-preview on competition math questions by up to 27% (MATH and AIME24). Further, scaling s1-32B with budget forcing allows extrapolating beyond its performance without test-time intervention: from 50% to 57% on AIME24. Our model, data, and code are open-source at https: //github.com/simplescaling/s1.
%G en
%A Muennighoff, Niklas
%A Yang, Zitong
%A Shi, Weijia
%A Li, Xiang Lisa
%A Fei-Fei, Li
%A Hajishirzi, Hannaneh
%A Zettlemoyer, Luke
%A Liang, Percy
%A Candès, Emmanuel
%A Hashimoto, Tatsunori
%D 2025-02-03
%K Computer Science - Artificial Intelligence
Computer Science - Computation and Language
Computer Science - Machine Learning

%0 Journal Article
%T Multiple-image optical encryption based on phase retrieval algorithm and fractional Talbot effect
%V 27
%N 24
%P 35096
%U https://opg.optica.org/abstract.cfm?URI=oe-27-24-35096
%X A new multiple-image optical encryption scheme based on phase retrieval algorithm and fractional Talbot eﬀect is proposed. In encryption process, by using Fresnel domain phase retrieval algorithm, each image is encoded into a pure phase distribution with diﬀerent spatial constraints. The spatial constraints are chosen as complementary square aperture array. A Talbot illuminator is designed according to the fractional Talbot eﬀect, which is treated as a decoder to obtain the designed square aperture array. Then all obtained phase distributions are combined into the ﬁnal ciphertext image. In decryption process, the images can be decoded from the ciphertext by using the Talbot illuminator and keys. Beneﬁt from the use of fractional Talbot eﬀect, the demultiplexing setup of the cryptosystem is very simple and straightforward, with no need of lens. The simulation results prove that the multiplexing capability is considerably enhanced. At the same time, the security analysis proves that the system can resist various attacks.
%G en
%J Optics Express
%A Wu, Jingjing
%A Wang, Jicheng
%A Nie, Yanguang
%A Hu, Lifa
%D 2019-11-25

%0 Journal Article
%T Experimental demonstration of passive microwave pulse amplification via temporal Talbot effect
%V 13
%N 1
%P 15330
%U https://www.nature.com/articles/s41598-023-42361-1
%X Abstract
            The temporal Talbot effect is a passive phenomenon that occurs when a periodic signal propagates through a dispersive medium with a quadratic phase response that modulates the output pulse repetition rate based on the input period. As previously proposed, this effect enables innovative applications such as passive amplification. However, its observation in the microwave regime has been impractical due to the requirement for controlled propagation through a highly dispersive waveguide. To overcome this challenge, we employed an ultra-wide band linearly chirped Bragg grating within a standard microwave X-Band waveguide. By utilizing backwards Talbot array illuminators aided by particle swarm optimization, we achieved passive amplification with a gain of 3.45 dB and 4.03 dB for gaussian and raised cosine pulses, respectively. Furthermore, we numerically verified that with higher quality substrates this gain can be theoretically increased to over 8 dB. Our work paves the way for numerous applications of the Talbot effect in the microwave regime, such as temporal cloaking, sub-noise microwave signal detection, microwave pulse shaping, and microwave noise reduction.
%G en
%J Scientific Reports
%A Pepino, Vinicius M.
%A Da Mota, Achiles F.
%A Borges, Ben-Hur V.
%D 2023-09-15

%0 Journal Article
%T Observation of Plasmonics Talbot effect in graphene nanostructures
%V 14
%N 1
%P 1973
%U https://www.nature.com/articles/s41598-024-52595-2
%X Abstract
            We report on the theoretical models of the plasmoincs Talbot effect in graphene nanostructure. The Talbot effect for the plasmonics applications in the IR range is theoretically studied and the respective Talbot effect for the novel advanced plasmonics structures are numerically investigated for the first time. It is shown that the metamaterial structures with periodic grating configuration represents a complex three-dimensional lattice of beamlet-like graphene plasmonics devices. The calculated results agree well with the experimental ones. The results obtained can be used to create and optimize the structures considering diffraction limit for a wide range of application areas. Effective focusing of plasmonic waves with exact focal spots and a subwavelength full width at half maximum can be obtained by using periodic graphene grating.
%G en
%J Scientific Reports
%A Farmani, Ali
%A Omidniaee, Anis
%D 2024-01-23

%0 Journal Article
%T Design and characterisation of a LIAD source in view of matter wave interferometry
%G en
%A Horak, Johannes Rudolf

%0 Journal Article
%T Angular Talbot effect
%V 112
%N 21
%P 213902
%* http://link.aps.org/licenses/aps-default-license
%U https://link.aps.org/doi/10.1103/PhysRevLett.112.213902
%G en
%J Physical Review Letters
%A Azaña, José
%A Guillet De Chatellus, Hugues
%D 2014-5-29

%0 Journal Article
%V 49
%N 11
%P 3070
%U https://opg.optica.org/abstract.cfm?URI=ol-49-11-3070
%X In this Letter, we demonstrate the generation of Hermite–Gaussian–Talbot carpets (HGTC) based on the interference of a Hermite–Gaussian (HG) beam array with constant successive separation (shift). Despite the acceleration of HG beams during propagation, their symmetric structure ensures that the self-imaged carpets are generated in straight lines perpendicular to the propagation direction, at particular distances, multiples of the famous Talbot distance
              z
              
                T
              
              . By considering the separation as a multiple or a fraction of the Hermite–Gaussian beam width, the calculated Talbot distance
              z
              
                T
              
              is expressed as a function of the beam parameters, such as the Rayleigh length. The same carpets are also observed in planes situated at different fractions of
              z
              
                T
              
              , but with different frequency appearances. An interesting feature of these carpets is that the dimension of one cell of the beam array remains constant in each period (period fraction). We believe that such novel, to our knowledge, carpets will be useful in photonics for creating lattices and optical potentials.
%G en
%J Optics Letters
%A Bencheikh, Abdelhalim
%A Deng, Dongmei
%D 2024-06-01

%0 Journal Article
%T Realization of optical carpets in the Talbot and Talbot-Lau configurations
%V 17
%N 23
%P 20966
%* https://doi.org/10.1364/OA_License_v1#VOR-OA
%U https://opg.optica.org/oe/abstract.cfm?uri=oe-17-23-20966
%X Talbot and Talbot-Lau effects are frequently used in lensless imaging applications with light, ultrasound, x-rays, atoms and molecules –generally in situations where refractive optical elements are non-existent or not suitable. We here show an experimental visualization of the intriguing wave patterns that are associated with near-ﬁeld interferometry behind a single periodic diffraction grating under plane wave illumination and which are often referred to as Talbot carpets or quantum carpets. We also show the patterns behind two separated diffraction gratings under nearly-monochromatic but spatially incoherent illumination that illustrate the nature of Talbot-Lau carpets.
%G en
%J Optics Express
%A Case, William B.
%A Tomandl, Mathias
%A Deachapunya, Sarayut
%A Arndt, Markus
%D 2009-11-09

%0 Journal Article
%T Fractional nonparaxial accelerating Talbot effect
%V 41
%N 14
%P 3273
%* https://doi.org/10.1364/OA_License_v1#VOR
%U https://opg.optica.org/abstract.cfm?URI=ol-41-14-3273
%G en
%J Optics Letters
%A Zhang, Yiqi
%A Zhong, Hua
%A Belić, Milivoj R.
%A Li, Changbiao
%A Zhang, Zhaoyang
%A Wen, Feng
%A Zhang, Yanpeng
%A Xiao, Min
%D 2016-07-15

%0 Journal Article
%T Fresnel diffraction in fractional Talbot planes: a new formulation
%V 11
%N 4
%P 1283
%* https://doi.org/10.1364/OA_License_v1#VOR
%U https://opg.optica.org/abstract.cfm?URI=josaa-11-4-1283
%G en
%J Journal of the Optical Society of America A
%A Westerholm, Jan
%A Turunen, Jari
%A Huttunen, Juhani
%D 1994-04-01

%0 Conference Paper
%T The fractional Talbot effect of two-dimensional array
%C San Diego, California, USA
%P 586712
%U http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.612711
%X In this paper, we theoretically prove the fractional self-imaging effect of the two-dimensional array with arbitrary shape and symmetry, using scalar diffraction theory and the known periodic self-Fourier-Fresnel transform function comb(x , y). As a result, we also got a general equation to calculate the phase of the fractional Talbot image of the two-dimensional array. As an example, we numerically evaluate the intensity distribution of the diamond array in triangular symmetry in the fractional Talbot plane using Matlab, The result is a good agreement with the theory.
%G en
%A Qu, Weijuan
%E Kahan, Mark A.
%A Liu, Liren
%A Liu, De'an
%A Luan, Zu
%A Xu, Nan
%D 2005-8-18

%0 Journal Article
%T Fractional Talbot effect: analysis in phase space
%V 13
%N 1
%P 119
%* https://doi.org/10.1364/OA_License_v1#VOR
%U https://opg.optica.org/abstract.cfm?URI=josaa-13-1-119
%X The Fresnel diffraction of periodic objects at rational fractions of the Talbot distance is described in terms of the Wigner distribution function (WDF). The analysis provides a heuristic model for understanding the formation of the diffraction patterns as well as for evaluating the complex amplitude at any fractional Talbot plane. Furthermore, certain symmetry properties of the Fresnel-diffracted wave field can be derived directly from the WDF. Additionally, a discussion is given on how periodic signals and information about the phase are encoded in the WDF.
%G en
%J Journal of the Optical Society of America A
%A Testorf, Markus
%A Ojeda-Castañeda, Jorge
%D 1996-01-01

%0 Journal Article
%T Fractional Talbot Effect: Compact Description
%V 7
%N 2
%P 129-131
%* http://www.springer.com/tdm
%U http://link.springer.com/10.1007/s10043-000-0129-3
%G en
%J Optical Review
%A Arrizón, Victor
%A Rojo-Velázquez, G.
%A Ibarra, Juan G.
%D 3/2000

%0 Journal Article
%T Integer, fractional and fractal Talbot effects
%V 43
%N 10
%P 2139-2164
%U http://www.tandfonline.com/doi/abs/10.1080/09500349608232876
%X Self-images of a grating with period a , illuminated by light of wavelength A, are produced at distances z that are rational multiples p / q of the Talbot distance 2 r = a Z / X ;each unit cell of a Talbot image consists of q superposed images of the grating. T h e phases of these individual images depend on the Gauss sums studied in number theory and are given explicitly in closed form; this simplifies calculations of the Talbot images. In ‘transverse’ planes, perpendicular to the incident light, and with C = z / z i~rrational, the intensity in the Talbot images is a fractal whose graph has dimension f. In ‘longitudinal’ planes, parallel to the incident light, and almost all oblique planes, the intensity is a fractal whose graph has dimension i.In certain special diagonal planes, the fractal dimension is $. Talbot images are sharp only in the paraxial approximation X/a + 0 and when the number N of illuminated slits tends to infinity. T h e universal form of the post-paraxial smoothing of the edge of the slit images is determined. An exact calculation gives the spatially averaged non-paraxial blurring within Talbot planes and defocusing between Talbot planes. Similar calculations are given for the blurring and defocusing produced by finite N. Experiments with a Ronchi grating confirm the existence of the longitudinal fractal, and the transverse Talbot fractal at the golden distance < = (3 - 5’/’)/2, within the expected resolutions.
%G en
%J Journal of Modern Optics
%A Berry, M. V.
%A Klein, S.
%D 10/1996

%0 Journal Article
%T Modeling wave propagation in damped waveguides of arbitrary cross-section
%V 295
%N 3-5
%P 685-707
%* https://www.elsevier.com/tdm/userlicense/1.0/
%U https://linkinghub.elsevier.com/retrieve/pii/S0022460X06001179
%X This paper deals with a semi-analytical ﬁnite element (SAFE) method for modeling wave propagation in waveguides of arbitrary cross-section. The method simply requires the ﬁnite element discretization of the cross-section of the waveguide, and assumes harmonic motion along the wave propagation direction. The general SAFE technique is extended to account for viscoelastic material damping by allowing for complex stiffness matrices for the material. The dispersive solutions are obtained in terms of phase velocity, group velocity (for undamped media), energy velocity (for damped media), attenuation, and cross-sectional mode shapes. Knowledge of these properties is important in any structural health monitoring attempt that uses ultrasonic guided waves. The proposed SAFE formulation is applied to several examples, including anisotropic viscoelastic layered plates, composite-to-composite adhesive joints and railroad tracks.
%G en
%J Journal of Sound and Vibration
%A Bartoli, Ivan
%A Marzani, Alessandro
%A Lanza Di Scalea, Francesco
%A Viola, Erasmo
%D 8/2006

%0 Journal Article
%T Free wave propagation in periodically supported, infinite beams
%V 11
%N 2
%P 181-197
%* https://www.elsevier.com/tdm/userlicense/1.0/
%U https://linkinghub.elsevier.com/retrieve/pii/S0022460X70800621
%G en
%J Journal of Sound and Vibration
%A Mead, D.J.
%D 2/1970

%0 Journal Article
%T Displacement Measurement Based on the Missing-Order Talbot Effect
%V 25
%N 1
%P 292
%* https://creativecommons.org/licenses/by/4.0/
%U https://www.mdpi.com/1424-8220/25/1/292
%X Displacement measurement is a crucial application, with laser-based methods offering high precision and being well established in commercial settings. However, these methods often come with the drawbacks of significant size and exorbitant costs. We introduce a novel displacement measurement method that utilizes the missing-order Talbot effect. This approach circumvents the need to measure contrast in the Talbot diffraction field, opting instead to leverage the displacement within the missing-order Talbot diffraction pattern. Our method only requires parallel light, an amplitude grating, and a detector to achieve displacement measurement. The measurement dynamic range can be adjusted by altering the grating period and the wavelength of the incident light. Through careful simulation and experimental validation, our method exhibits a correlation coefficient R surpassing 0.999 across a 30 mm dynamic range and achieves a precision superior to 3 µm.
%G en
%J Sensors
%A Song, Liuxing
%A Zhao, Kailun
%A Wang, Xiaoyong
%A He, Jinping
%A Tian, Guoliang
%A Yang, Shihua
%A Li, Yaning
%D 2025-01-06

%0 Journal Article
%T Eigenvectors from eigenvalues: A survey of a basic identity in linear algebra
%V 59
%N 1
%P 31-58
%U http://arxiv.org/abs/1908.03795
%X If $A$ is an $n \times n$ Hermitian matrix with eigenvalues $\lambda_1(A),\dots,\lambda_n(A)$ and $i,j = 1,\dots,n$, then the $j^{\mathrm{th}}$ component $v_{i,j}$ of a unit eigenvector $v_i$ associated to the eigenvalue $\lambda_i(A)$ is related to the eigenvalues $\lambda_1(M_j),\dots,\lambda_{n-1}(M_j)$ of the minor $M_j$ of $A$ formed by removing the $j^{\mathrm{th}}$ row and column by the formula $$ |v_{i,j}|^2\prod_{k=1;k\neq i}^{n}\left(\lambda_i(A)-\lambda_k(A)\right)=\prod_{k=1}^{n-1}\left(\lambda_i(A)-\lambda_k(M_j)\right)\,.$$ We refer to this identity as the \emph{eigenvector-eigenvalue identity} and show how this identity can also be used to extract the relative phases between the components of any given eigenvector. Despite the simple nature of this identity and the extremely mature state of development of linear algebra, this identity was not widely known until very recently. In this survey we describe the many times that this identity, or variants thereof, have been discovered and rediscovered in the literature (with the earliest precursor we know of appearing in 1834). We also provide a number of proofs and generalizations of the identity.
%G en
%J Bulletin of the American Mathematical Society
%A Denton, Peter B.
%A Parke, Stephen J.
%A Tao, Terence
%A Zhang, Xining
%D 2021-2-18
%K High Energy Physics - Phenomenology
High Energy Physics - Theory
Mathematical Physics
Mathematics - Mathematical Physics
Mathematics - Rings and Algebras

%0 Journal Article
%T Modeling wave propagation in damped waveguides of arbitrary cross-section
%V 295
%N 3-5
%P 685-707
%* https://www.elsevier.com/tdm/userlicense/1.0/
%U https://linkinghub.elsevier.com/retrieve/pii/S0022460X06001179
%X This paper deals with a semi-analytical ﬁnite element (SAFE) method for modeling wave propagation in waveguides of arbitrary cross-section. The method simply requires the ﬁnite element discretization of the cross-section of the waveguide, and assumes harmonic motion along the wave propagation direction. The general SAFE technique is extended to account for viscoelastic material damping by allowing for complex stiffness matrices for the material. The dispersive solutions are obtained in terms of phase velocity, group velocity (for undamped media), energy velocity (for damped media), attenuation, and cross-sectional mode shapes. Knowledge of these properties is important in any structural health monitoring attempt that uses ultrasonic guided waves. The proposed SAFE formulation is applied to several examples, including anisotropic viscoelastic layered plates, composite-to-composite adhesive joints and railroad tracks.
%G en
%J Journal of Sound and Vibration
%A Bartoli, Ivan
%A Marzani, Alessandro
%A Lanza Di Scalea, Francesco
%A Viola, Erasmo
%D 8/2006

%0 Journal Article
%T Tunable elastic wave propagation in planar functionally graded metamaterials
%V 231
%N 8
%P 3363-3385
%U https://link.springer.com/10.1007/s00707-020-02705-8
%X Structures made of functionally graded materials (FGM) are successful attempts to enhance the mechanical properties of homogeneous materials. On the other hand, periodically architected structures provide phenomenal opportunities to design structures much lighter than their bulk counterparts showing exceptional mechanical characteristics. In the present study, to utilize the advantages of both technologies, wave propagation properties of functionally graded metamaterials (FGMM), i.e., periodically architected structures made of FGM, are investigated for three different planar topologies, and their vibration ﬁltering performances are analyzed. The mathematical formulations to obtain the equation of motion for the FGMM are developed using the ﬁnite element method, and Floquet–Bloch’s theorem is employed to ﬁnd their dispersion curves. Periodically architected structures with hexagonal, rectangular, and triangular unit cells are considered, and the effects of the FGM on their stop-band percentages are investigated. A comparison between band structures of pure steel (St), pure alumina (Al2O3) and St−Al2O3 reveals that using FGM in the periodically architected structures can greatly enhance wave propagation properties by opening new stop-band regions leading to structures with much more versatility and tunability. The material distribution is assumed to vary according to both power-law and exponential-law rules along the beam axis and thickness, and the effects of Young’s modulus ratio, density ratio, relative density, and non-negative power-law exponent are scrutinized on the bandgap properties. The results indicate that periodically architected structures made of FGM exhibit much higher percentages of stop-bands, and playing with corresponding FGM parameters can tune this value for desired engineering needs. In addition, a mathematical approach is presented to investigate the polarization of the studied FGMM in the longitudinal, transverse, and rotational directions, and to measure the effects of material distribution on the polarization of the ﬁrst three branches of the dispersion curves. It is revealed that the polarization factors of the three ﬁrst dispersion branches are mainly geometry-dependent and change slightly with the material distribution.
%G en
%J Acta Mechanica
%A Sepehri, Soroush
%A Jafari, Hamid
%A Mosavi Mashhadi, Mahmoud
%A Hairi Yazdi, Mohammad Reza
%A Seyyed Fakhrabadi, Mir Masoud
%D 08/2020

%0 Journal Article
%T FairXAI -A Taxonomy and Framework for Fairness and Explainability Synergy in Machine Learning
%P 1-18
%* https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html
%U https://ieeexplore.ieee.org/document/10848523/
%X Explainable artificial intelligence (XAI) and fair learning have made significant strides in various application domains, including criminal recidivism predictions, healthcare settings, toxic comment detection, automatic speech detection, recommendation systems, and image segmentation. However, these two fields have largely evolved independently. Recent studies have demonstrated that incorporating explanations into decision-making processes enhances the transparency and trustworthiness of AI systems. In light of this, our objective is to conduct a systematic review of FairXAI, which explores the interplay between fairness and explainability frameworks. To commence, we propose a taxonomy of FairXAI that utilizes XAI to mitigate and evaluate bias. This taxonomy will be a base for machine learning researchers operating in diverse domains. Additionally, we will undertake an extensive review of existing articles, taking into account factors such as the purpose of the interaction, target audience, and domain and context. Moreover, we outline an interaction framework for FairXAI considering various fairness perceptions and propose a FairXAI wheel that encompasses four core properties that must be verified and evaluated. This will serve as a practical tool for researchers and practitioners, ensuring the fairness and transparency of their AI systems. Furthermore, we will identify challenges and conflicts in the interactions between fairness and explainability, which could potentially pave the way for enhancing the responsibility of AI systems. As the inaugural review of its kind, we hope that this survey will inspire scholars to address these challenges by scrutinizing current research in their respective domains.
%G en
%J IEEE Transactions on Neural Networks and Learning Systems
%A Ramachandranpillai, Resmi
%A Baeza-Yates, Ricardo
%A Heintz, Fredrik
%D 2025

%0 Journal Article
%T LEMMA: Learning Language-Conditioned Multi-Robot Manipulation
%V 8
%N 10
%P 6835-6842
%* https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html
%U https://ieeexplore.ieee.org/document/10243083/
%X Complex manipulation tasks often require robots with complementary capabilities to collaborate. We introduce a benchmark for LanguagE-Conditioned Multi-robot MAnipulation (LEMMA) focused on task allocation and long-horizon object manipulation based on human language instructions in a tabletop setting. LEMMA features 8 types of procedurally generated tasks with varying degree of complexity, some of which require the robots to use tools and pass tools to each other. For each task, we provide 800 expert demonstrations and human instructions for training and evaluations. LEMMA poses greater challenges compared to existing benchmarks, as it requires the system to identify each manipulator’s limitations and assign sub-tasks accordingly while also handling strong temporal dependencies in each task. To address these challenges, we propose a modular hierarchical planning approach as a baseline. Our results highlight the potential of LEMMA for developing future language-conditioned multi-robot systems.
%G en
%J IEEE Robotics and Automation Letters
%A Gong, Ran
%A Gao, Xiaofeng
%A Gao, Qiaozi
%A Shakiah, Suhaila
%A Thattai, Govind
%A Sukhatme, Gaurav S.
%D 10/2023

%0 Journal Article
%T Multimodal Learning With Transformers: A Survey
%V 45
%N 10
%P 12113-12132
%* https://creativecommons.org/licenses/by/4.0/legalcode
%U https://ieeexplore.ieee.org/document/10123038/
%X Transformer is a promising neural network learner, and has achieved great success in various machine learning tasks. Thanks to the recent prevalence of multimodal applications and big data, Transformer-based multimodal learning has become a hot topic in AI research. This paper presents a comprehensive survey of Transformer techniques oriented at multimodal data. The main contents of this survey include: (1) a background of multimodal learning, Transformer ecosystem, and the multimodal big data era, (2) a systematic review of Vanilla Transformer, Vision Transformer, and multimodal Transformers, from a geometrically topological perspective, (3) a review of multimodal Transformer applications, via two important paradigms, i.e., for multimodal pretraining and for specific multimodal tasks, (4) a summary of the common challenges and designs shared by the multimodal Transformer models and applications, and (5) a discussion of open problems and potential research directions for the community.
%G en
%J IEEE Transactions on Pattern Analysis and Machine Intelligence
%A Xu, Peng
%A Zhu, Xiatian
%A Clifton, David A.
%D 10/2023

%0 Journal Article
%T A Comprehensive Survey of Continual Learning: Theory, Method and Application
%V 46
%N 8
%P 5362-5383
%* https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html
%U https://ieeexplore.ieee.org/document/10444954/
%X To cope with real-world dynamics, an intelligent system needs to incrementally acquire, update, accumulate, and exploit knowledge throughout its lifetime. This ability, known as continual learning, provides a foundation for AI systems to develop themselves adaptively. In a general sense, continual learning is explicitly limited by catastrophic forgetting, where learning a new task usually results in a dramatic performance drop of the old tasks. Beyond this, increasingly numerous advances have emerged in recent years that largely extend the understanding and application of continual learning. The growing and widespread interest in this direction demonstrates its realistic signiﬁcance as well as complexity. In this work, we present a comprehensive survey of continual learning, seeking to bridge the basic settings, theoretical foundations, representative methods, and practical applications. Based on existing theoretical and empirical results, we summarize the general objectives of continual learning as ensuring a proper stability-plasticity trade-off and an adequate intra/inter-task generalizability in the context of resource efﬁciency. Then we provide a state-of-the-art and elaborated taxonomy, extensively analyzing how representative strategies address continual learning, and how they are adapted to particular challenges in various applications. Through an in-depth discussion of promising directions, we believe that such a holistic perspective can greatly facilitate subsequent exploration in this ﬁeld and beyond.
%G en
%J IEEE Transactions on Pattern Analysis and Machine Intelligence
%A Wang, Liyuan
%A Zhang, Xingxing
%A Su, Hang
%A Zhu, Jun
%D 8/2024

%0 Journal Article
%T Temporal Talbot effect in fiber gratings and its applications
%V 38
%N 32
%P 6700
%* https://doi.org/10.1364/OA_License_v1#VOR
%U https://opg.optica.org/abstract.cfm?URI=ao-38-32-6700
%G en
%J Applied Optics
%A Azaña, José
%A Muriel, Miguel A.
%D 1999-11-10

%0 Journal Article
%T Full space-time Talbot effect
%V 33
%N 5
%P 12147
%U https://opg.optica.org/abstract.cfm?URI=oe-33-5-12147
%X The Talbot effect, a well-established phenomenon in optics, has been a subject of extensive research for many years. Recently, there has been growing interest in its periodic revival within periodically structured light fields during free propagation, driving innovative advancements in spatial, temporal, and space-time Talbot effects. However, studies of the Talbot effect in such structured light fields have remained confined to two-dimensional configurations in the X-T plane, with no exploration of multidimensional structured light fields. In this paper, we propose a new class of three-dimensional periodic structured light fields that exhibit the Talbot effect in full space-time. With an additional dimension given, full space-time Talbot light fields with different properties, such as uneven spatiotemporal Talbot effect, carrying longitudinal orbital angular momentum, and spatiotemporal spiral light fields are studied. In the future, this new type of space-time light field with multidimensional control may lead to new properties and a broader range of potential applications.
%G en
%J Optics Express
%A Zhang, Yuman
%A Cao, Qian
%A Chong, Andy
%A Zhan, Qiwen
%D 2025-03-10

%0 Journal Article
%T Temporal Talbot effect in free space
%V 46
%N 13
%P 3107
%U https://opg.optica.org/abstract.cfm?URI=ol-46-13-3107
%X The temporal Talbot effect refers to the periodic revivals of a pulse train propagating in a dispersive medium and is a temporal analog of the spatial Talbot effect with group-velocity dispersion in time replacing diffraction in space. Because of typically large temporal Talbot lengths, this effect has been observed to date in only single-mode fibers, rather than with freely propagating fields in bulk dispersive media. Here we demonstrate for the first time, to the best of our knowledge, the temporal Talbot effect in free space by employing dispersive space-time wave packets, whose spatiotemporal structure induces group-velocity dispersion of controllable magnitude and sign in free space.
%G en
%J Optics Letters
%A Hall, Layton A.
%A Ponomarenko, Sergey
%A Abouraddy, Ayman F.
%D 2021-07-01

%0 Generic
%T Vision+X: A Survey on Multimodal Learning in the Light of Data
%I arXiv
%U http://arxiv.org/abs/2210.02884
%X We are perceiving and communicating with the world in a multisensory manner, where different information sources are sophisticatedly processed and interpreted by separate parts of the human brain to constitute a complex, yet harmonious and unified sensing system. To endow the machines with true intelligence, multimodal machine learning that incorporates data from various sources has become an increasingly popular research area with emerging technical advances in recent years. In this paper, we present a survey on multimodal machine learning from a novel perspective considering not only the purely technical aspects but also the intrinsic nature of different data modalities. We analyze the commonness and uniqueness of each data format mainly ranging from vision, audio, text, and motions, and then present the methodological advancements categorized by the combination of data modalities, such as Vision+Text, with slightly inclined emphasis on the visual data. We investigate the existing literature on multimodal learning from both the representation learning and downstream application levels, and provide an additional comparison in the light of their technical connections with the data nature, e.g., the semantic consistency between image objects and textual descriptions, and the rhythm correspondence between video dance moves and musical beats. We hope that the exploitation of the alignment as well as the existing gap between the intrinsic nature of data modality and the technical designs, will benefit future research studies to better address a specific challenge related to the concrete multimodal task, prompting a unified multimodal machine learning framework closer to a real human intelligence system.
%G en
%A Zhu, Ye
%A Wu, Yu
%A Sebe, Nicu
%A Yan, Yan
%D 2024-06-07
%K Computer Science - Computer Vision and Pattern Recognition

%0 Generic
%T VCoder: Versatile Vision Encoders for Multimodal Large Language Models
%I arXiv
%U http://arxiv.org/abs/2312.14233
%X Humans possess the remarkable skill of Visual Perception, the ability to see and understand the seen, helping them make sense of the visual world and, in turn, reason. Multimodal Large Language Models (MLLM) have recently achieved impressive performance on vision-language tasks ranging from visual question-answering and image captioning to visual reasoning and image generation. However, when prompted to identify or count (perceive) the entities in a given image, existing MLLM systems fail. Working towards developing an accurate MLLM system for perception and reasoning, we propose using Versatile vision enCoders (VCoder) as perception eyes for Multimodal LLMs. We feed the VCoder with perception modalities such as segmentation or depth maps, improving the MLLM’s perception abilities. Secondly, we leverage the images from COCO and outputs from off-the-shelf vision perception models to create our COCO Segmentation Text (COST) dataset for training and evaluating MLLMs on the object perception task. Thirdly, we introduce metrics to assess the object perception abilities in MLLMs on our COST dataset. Lastly, we provide extensive experimental evidence proving the VCoder’s improved object-level perception skills over existing Multimodal LLMs, including GPT-4V. We open-source our dataset, code, and models to promote research.
%G en
%A Jain, Jitesh
%A Yang, Jianwei
%A Shi, Humphrey
%D 2023-12-21
%K Computer Science - Computer Vision and Pattern Recognition

%0 Generic
%T Debiased Multimodal Understanding for Human Language Sequences
%I arXiv
%U http://arxiv.org/abs/2403.05025
%X Human multimodal language understanding (MLU) is an indispensable component of expression analysis (e.g., sentiment or humor) from heterogeneous modalities, including visual postures, linguistic contents, and acoustic behaviours. Existing works invariably focus on designing sophisticated structures or fusion strategies to achieve impressive improvements. Unfortunately, they all suffer from the subject variation problem due to data distribution discrepancies among subjects. Concretely, MLU models are easily misled by distinct subjects with different expression customs and characteristics in the training data to learn subject-specific spurious correlations, limiting performance and generalizability across new subjects. Motivated by this observation, we introduce a recapitulative causal graph to formulate the MLU procedure and analyze the confounding effect of subjects. Then, we propose SuCI, a simple yet effective causal intervention module to disentangle the impact of subjects acting as unobserved confounders and achieve model training via true causal effects. As a plug-and-play component, SuCI can be widely applied to most methods that seek unbiased predictions. Comprehensive experiments on several MLU benchmarks clearly show the effectiveness of the proposed module.
%G en
%A Xu, Zhi
%A Yang, Dingkang
%A Li, Mingcheng
%A Wang, Yuzheng
%A Chen, Zhaoyu
%A Chen, Jiawei
%A Wei, Jinjie
%A Zhang, Lihua
%D 2024-12-13
%K Computer Science - Artificial Intelligence

%0 Generic
%T Compositional Entailment Learning for Hyperbolic Vision-Language Models
%I arXiv
%U http://arxiv.org/abs/2410.06912
%X Image-text representation learning forms a cornerstone in vision-language models, where pairs of images and textual descriptions are contrastively aligned in a shared embedding space. Since visual and textual concepts are naturally hierarchical, recent work has shown that hyperbolic space can serve as a high-potential manifold to learn vision-language representation with strong downstream performance. In this work, for the first time we show how to fully leverage the innate hierarchical nature of hyperbolic embeddings by looking beyond individual image-text pairs. We propose Compositional Entailment Learning for hyperbolic vision-language models. The idea is that an image is not only described by a sentence but is itself a composition of multiple object boxes, each with their own textual description. Such information can be obtained freely by extracting nouns from sentences and using openly available localized grounding models. We show how to hierarchically organize images, image boxes, and their textual descriptions through contrastive and entailment-based objectives. Empirical evaluation on a hyperbolic visionlanguage model trained with millions of image-text pairs shows that the proposed compositional learning approach outperforms conventional Euclidean CLIP learning, as well as recent hyperbolic alternatives, with better zero-shot and retrieval generalization and clearly stronger hierarchical performance. Code available at https://github.com/PalAvik/hycoclip.
%G en
%A Pal, Avik
%A Spengler, Max van
%A Melendugno, Guido Maria D'Amely di
%A Flaborea, Alessandro
%A Galasso, Fabio
%A Mettes, Pascal
%D 2025-03-01
%K Computer Science - Artificial Intelligence
Computer Science - Machine Learning
Computer Science - Computer Vision and Pattern Recognition

%0 Generic
%T Dense Audio-Visual Event Localization under Cross-Modal Consistency and Multi-Temporal Granularity Collaboration
%I arXiv
%U http://arxiv.org/abs/2412.12628
%X In the field of audio-visual learning, most research tasks focus exclusively on short videos. This paper focuses on the more practical Dense Audio-Visual Event Localization (DAVEL) task, advancing audio-visual scene understanding for longer, untrimmed videos. This task seeks to identify and temporally pinpoint all events simultaneously occurring in both audio and visual streams. Typically, each video encompasses dense events of multiple classes, which may overlap on the timeline, each exhibiting varied durations. Given these challenges, effectively exploiting the audio-visual relations and the temporal features encoded at various granularities becomes crucial. To address these challenges, we introduce a novel CCNet, comprising two core modules: the Cross-Modal Consistency Collaboration (CMCC) and the Multi-Temporal Granularity Collaboration (MTGC). Specifically, the CMCC module contains two branches: a cross-modal interaction branch and a temporal consistency-gated branch. The former branch facilitates the aggregation of consistent event semantics across modalities through the encoding of audio-visual relations, while the latter branch guides one modality’s focus to pivotal event-relevant temporal areas as discerned in the other modality. The MTGC module includes a coarse-to-fine collaboration block and a fine-to-coarse collaboration block, providing bidirectional support among coarse- and fine-grained temporal features. Extensive experiments on the UnAV-100 dataset validate our module design, resulting in a new state-of-the-art performance in dense audio-visual event localization. The code is available at https://github.com/zzhhfut/CCNet-AAAI2025.
%G en
%A Zhou, Ziheng
%A Zhou, Jinxing
%A Qian, Wei
%A Tang, Shengeng
%A Chang, Xiaojun
%A Guo, Dan
%D 2024-12-18
%K Computer Science - Computer Vision and Pattern Recognition

%0 Generic
%T Predictive Dynamic Fusion
%I arXiv
%U http://arxiv.org/abs/2406.04802
%X Multimodal fusion is crucial in joint decisionmaking systems for rendering holistic judgments. Since multimodal data changes in open environments, dynamic fusion has emerged and achieved remarkable progress in numerous applications. However, most existing dynamic multimodal fusion methods lack theoretical guarantees and easily fall into suboptimal problems, yielding unreliability and instability. To address this issue, we propose a Predictive Dynamic Fusion (PDF) framework for multimodal learning. We proceed to reveal the multimodal fusion from a generalization perspective and theoretically derive the predictable Collaborative Belief (Co-Belief) with Mono- and Holo-Confidence, which provably reduces the upper bound of generalization error. Accordingly, we further propose a relative calibration strategy to calibrate the predicted CoBelief for potential uncertainty. Extensive experiments on multiple benchmarks confirm our superiority. Our code is available at https: //github.com/Yinan-Xia/PDF.
%G en
%A Cao, Bing
%A Xia, Yinan
%A Ding, Yi
%A Zhang, Changqing
%A Hu, Qinghua
%D 2024-11-05
%K Computer Science - Machine Learning
Computer Science - Computer Vision and Pattern Recognition

%0 Generic
%T Multimodality Helps Few-shot 3D Point Cloud Semantic Segmentation
%I arXiv
%U http://arxiv.org/abs/2410.22489
%X Few-shot 3D point cloud segmentation (FS-PCS) aims at generalizing models to segment novel categories with minimal annotated support samples. While existing FS-PCS methods have shown promise, they primarily focus on unimodal point cloud inputs, overlooking the potential benefits of leveraging multimodal information. In this paper, we address this gap by introducing a multimodal FS-PCS setup, utilizing textual labels and the potentially available 2D image modality. Under this easy-to-achieve setup, we present the MultiModal Few-Shot SegNet (MM-FSS), a model effectively harnessing complementary information from multiple modalities. MM-FSS employs a shared backbone with two heads to extract intermodal and unimodal visual features, and a pretrained text encoder to generate text embeddings. To fully exploit the multimodal information, we propose a Multimodal Correlation Fusion (MCF) module to generate multimodal correlations, and a Multimodal Semantic Fusion (MSF) module to refine the correlations using text-aware semantic guidance. Additionally, we propose a simple yet effective Test-time Adaptive Cross-modal Calibration (TACC) technique to mitigate training bias, further improving generalization. Experimental results on S3DIS and ScanNet datasets demonstrate significant performance improvements achieved by our method. The efficacy of our approach indicates the benefits of leveraging commonly-ignored free modalities for FS-PCS, providing valuable insights for future research. The code is available at this link.
%G en
%A An, Zhaochong
%A Sun, Guolei
%A Liu, Yun
%A Li, Runjia
%A Wu, Min
%A Cheng, Ming-Ming
%A Konukoglu, Ender
%A Belongie, Serge
%D 2025-02-26
%K Computer Science - Computer Vision and Pattern Recognition

%0 Journal Article
%T Observation of the Talbot effect with water waves
%V 87
%N 1
%P 38-43
%U https://pubs.aip.org/ajp/article/87/1/38/1057526/Observation-of-the-Talbot-effect-with-water-waves
%X When light is incident upon a diffraction grating, images of the grating appear at periodic intervals behind the grating. This phenomenon and the associated self-imaging distance were named after Talbot, who first observed them in the nineteenth century. A century later, this effect held new surprises with the discovery of sub-images at regular fractional distances of the Talbot length. In this paper, we show that water waves enable one to observe the Talbot effect in a classroom experiment. Quantitative measurements, of for example the Talbot distances, can be performed with an easy-to-use digital Schlieren method.
%G en
%J American Journal of Physics
%A Bakman, Alexandra
%A Fishman, Shmuel
%A Fink, Mathias
%A Fort, Emmanuel
%A Wildeman, Sander
%D 2019-01-01

%0 Journal Article
%T Active encoding of flexural wave with non-diffractive Talbot effect
%V 14
%N 1
%P 22573
%U https://doi.org/10.1038/s41598-024-73189-y
%X In this paper, a flexural Mikaelian lens in thin plate is designed by using conformation transformation. The propagation characteristics of flexural waves in the lens are investigated through rays trajectory equation, simulation analyses, and experimental tests, confirming the self-focusing properties of the Mikaelian lens. Additionally, the study explores the Talbot effect for flexural waves, revealing through simulation studies that the Talbot effect within the Mikaelian lens exhibits nearly diffraction-free properties. Building on the non-diffractive nature of the Talbot effect within the Mikaelian lens, we explore the potential for encoding flexural waves using active interference sources. The simulation and experiment results demonstrate the good performance of the designed active encoding system. This work opens up new avenues for the encoding of flexural waves, presenting promising implications for applications in communication such as structural health monitoring, wireless communication in solid media and data transmission in robotics and other areas related to flexural wave technology.
%J Scientific Reports
%A Li, Zhiqiang
%A Liu, Kaiming
%A Li, Chunlin
%A Liu, Yongquan
%A Du, Yanping
%A Li, Ting
%A Sun, Zhaoyong
%A Zhao, Liuxian
%A Yang, Jun
%D 2024-09-29

%0 Journal Article
%T Active encoding of flexural wave with non-diffractive Talbot effect
%V 14
%N 1
%P 22573
%U https://doi.org/10.1038/s41598-024-73189-y
%X In this paper, a flexural Mikaelian lens in thin plate is designed by using conformation transformation. The propagation characteristics of flexural waves in the lens are investigated through rays trajectory equation, simulation analyses, and experimental tests, confirming the self-focusing properties of the Mikaelian lens. Additionally, the study explores the Talbot effect for flexural waves, revealing through simulation studies that the Talbot effect within the Mikaelian lens exhibits nearly diffraction-free properties. Building on the non-diffractive nature of the Talbot effect within the Mikaelian lens, we explore the potential for encoding flexural waves using active interference sources. The simulation and experiment results demonstrate the good performance of the designed active encoding system. This work opens up new avenues for the encoding of flexural waves, presenting promising implications for applications in communication such as structural health monitoring, wireless communication in solid media and data transmission in robotics and other areas related to flexural wave technology.
%J Scientific Reports
%A Li, Zhiqiang
%A Liu, Kaiming
%A Li, Chunlin
%A Liu, Yongquan
%A Du, Yanping
%A Li, Ting
%A Sun, Zhaoyong
%A Zhao, Liuxian
%A Yang, Jun
%D 2024-09-29

%0 Journal Article
%T Active encoding of flexural wave with non-diffractive Talbot effect
%V 14
%N 1
%P 22573
%U https://www.nature.com/articles/s41598-024-73189-y
%G en
%J Scientific Reports
%A Li, Zhiqiang
%A Liu, Kaiming
%A Li, Chunlin
%A Liu, Yongquan
%A Du, Yanping
%A Li, Ting
%A Sun, Zhaoyong
%A Zhao, Liuxian
%A Yang, Jun
%D 2024-09-29

%0 Conference Paper
%T A Unified Framework for Deep Symbolic Regression
%X The last few years have witnessed a surge in methods for symbolic regression, from advances in traditional evolutionary approaches to novel deep learning-based systems. Individual works typically focus on advancing the state-of-the-art for one particular class of solution strategies, and there have been few attempts to investigate the beneﬁts of hybridizing or integrating multiple strategies. In this work, we identify ﬁve classes of symbolic regression solution strategies—recursive problem simpliﬁcation, neural-guided search, large-scale pre-training, genetic programming, and linear models—and propose a strategy to hybridize them into a single modular, uniﬁed symbolic regression framework. Based on empirical evaluation using SRBench, a new community tool for benchmarking symbolic regression methods, our uniﬁed framework achieves state-of-the-art performance in its ability to (1) symbolically recover analytical expressions, (2) ﬁt datasets with high accuracy, and (3) balance accuracy-complexity trade-offs, across 252 ground-truth and black-box benchmark problems, in both noiseless settings and across various noise levels. Finally, we provide practical use case-based guidance for constructing hybrid symbolic regression algorithms, supported by extensive, combinatorial ablation studies.
%G en
%B NeurIPS 2022
%A Landajuela, Mikel
%A Lee, Chak Shing
%A Yang, Jiachen
%A Glatt, Ruben
%A Santiago, Claudio
%A Mundhenk, T Nathan
%A Aravena, Ignacio
%A Mulcahy, Garrett
%A Petersen, Brenden
%D 2022

%0 Journal Article
%T Artificial Intelligence in Physical Sciences: Symbolic Regression Trends and Perspectives
%V 30
%N 6
%P 3845-3865
%U https://link.springer.com/10.1007/s11831-023-09922-z
%X Symbolic regression (SR) is a machine learning-based regression method based on genetic programming principles that integrates techniques and processes from heterogeneous scientific fields and is capable of providing analytical equations purely from data. This remarkable characteristic diminishes the need to incorporate prior knowledge about the investigated system. SR can spot profound and elucidate ambiguous relations that can be generalizable, applicable, explainable and span over most scientific, technological, economical, and social principles. In this review, current state of the art is documented, technical and physical characteristics of SR are presented, the available programming techniques are investigated, fields of application are explored, and future perspectives are discussed.
%G en
%J Archives of Computational Methods in Engineering
%A Angelis, Dimitrios
%A Sofos, Filippos
%A Karakasidis, Theodoros E.
%D 07/2023

%0 Journal Article
%T AI Feynman: A physics-inspired method for symbolic regression
%V 6
%N 16
%P eaay2631
%U https://www.science.org/doi/10.1126/sciadv.aay2631
%X 【AIFeynman，曾经的GOAT】
Our physics-inspired algorithm for symbolic regression is able to discover complex physics equations from mere tables of numbers.
              A core challenge for both physics and artificial intelligence (AI) is symbolic regression: finding a symbolic expression that matches data from an unknown function. Although this problem is likely to be NP-hard in principle, functions of practical interest often exhibit symmetries, separability, compositionality, and other simplifying properties. In this spirit, we develop a recursive multidimensional symbolic regression algorithm that combines neural network fitting with a suite of physics-inspired techniques. We apply it to 100 equations from the
              Feynman Lectures on Physics
              , and it discovers all of them, while previous publicly available software cracks only 71; for a more difficult physics-based test set, we improve the state-of-the-art success rate from 15 to 90%.
%G en
%J Science Advances
%A Udrescu, Silviu-Marian
%A Tegmark, Max
%D 2020-04-17

%0 Journal Article
%T SymFormer: End-to-End Symbolic Regression Using Transformer-Based Architecture
%V 12
%P 37840-37849
%* https://creativecommons.org/licenses/by/4.0/legalcode
%U https://ieeexplore.ieee.org/document/10462113/
%X Many real-world systems can be naturally described by mathematical formulas. The task of automatically constructing formulas to fit observed data is called symbolic regression. Evolutionary methods such as genetic programming have been commonly used to solve symbolic regression tasks, but they have significant drawbacks, such as high computational complexity. Recently, neural networks have been applied to symbolic regression, among which the transformer-based methods seem to be most promising. After training a transformer on a large number of formulas, the actual inference, i.e., finding a formula for new, unseen data, is very fast (in the order of seconds). This is considerably faster than state-ofthe-art evolutionary methods. The main drawback of transformers is that they generate formulas without numerical constants, which have to be optimized separately, yielding suboptimal results. We propose a transformer-based approach called SymFormer, which predicts the formula by outputting the symbols and the constants simultaneously. This helps to generate formulas that fit the data more accurately. In addition, the constants provided by SymFormer serve as a good starting point for subsequent tuning via gradient descent to further improve the model accuracy. We show on several benchmarks that SymFormer outperforms stateof-the-art methods while having faster inference.
%G en
%J IEEE Access
%A Vastl, Martin
%A Kulhánek, Jonáš
%A Kubalík, Jiří
%A Derner, Erik
%A Babuška, Robert
%D 2024

%0 Journal Article
%T Interpretable scientific discovery with symbolic regression: a review
%V 57
%N 1
%P 2
%U https://link.springer.com/10.1007/s10462-023-10622-0
%X Symbolic regression is emerging as a promising machine learning method for learning succinct underlying interpretable mathematical expressions directly from data. Whereas it has been traditionally tackled with genetic programming, it has recently gained a growing interest in deep learning as a data-driven model discovery tool, achieving significant advances in various application domains ranging from fundamental to applied sciences. In this survey, we present a structured and comprehensive overview of symbolic regression methods, review the adoption of these methods for model discovery in various areas, and assess their effectiveness. We have also grouped state-of-the-art symbolic regression applications in a categorized manner in a living review.
%G en
%J Artificial Intelligence Review
%A Makke, Nour
%A Chawla, Sanjay
%D 01/2024

%0 Journal Article
%T Toward Physically Plausible Data-Driven Models: A Novel Neural Network Approach to Symbolic Regression
%V 11
%P 61481-61501
%* https://creativecommons.org/licenses/by/4.0/legalcode
%U https://ieeexplore.ieee.org/document/10155126/
%X Many real-world systems can be described by mathematical models that are humancomprehensible, easy to analyze and help explain the system’s behavior. Symbolic regression is a method that can automatically generate such models from data. Historically, symbolic regression has been predominantly realized by genetic programming, a method that evolves populations of candidate solutions that are subsequently modified by genetic operators crossover and mutation. However, this approach suffers from several deficiencies: it does not scale well with the number of variables and samples in the training data –models tend to grow in size and complexity without an adequate accuracy gain, and it is hard to fine-tune the model coefficients using just genetic operators. Recently, neural networks have been applied to learn the whole analytic model, i.e., its structure and the coefficients, using gradient-based optimization algorithms. This paper proposes a novel neural network-based symbolic regression method that constructs physically plausible models based on even very small training data sets and prior knowledge about the system. The method employs an adaptive weighting scheme to effectively deal with multiple loss function terms and an epoch-wise learning process to reduce the chance of getting stuck in poor local optima. Furthermore, we propose a parameter-free method for choosing the model with the best interpolation and extrapolation performance out of all the models generated throughout the whole learning process. We experimentally evaluate the approach on four test systems: the TurtleBot 2 mobile robot, the magnetic manipulation system, the equivalent resistance of two resistors in parallel, and the longitudinal force of the anti-lock braking system. The results clearly show the potential of the method to find parsimonious models that comply with the prior knowledge provided.
%G en
%J IEEE Access
%A Kubalík, Jiří
%A Derner, Erik
%A Babuška, Robert
%D 2023

%0 Journal Article
%T A computational framework for physics-informed symbolic regression with straightforward integration of domain knowledge
%V 13
%N 1
%P 1249
%U https://www.nature.com/articles/s41598-023-28328-2
%X Discovering a meaningful symbolic expression that explains experimental data is a fundamental challenge in many scientific fields. We present a novel, open-source computational framework called
              Scientist-Machine Equation Detector
              (SciMED), which integrates scientific discipline wisdom in a scientist-in-the-loop approach, with state-of-the-art symbolic regression (SR) methods. SciMED combines a wrapper selection method, that is based on a genetic algorithm, with automatic machine learning and two levels of SR methods. We test SciMED on five configurations of a settling sphere, with and without aerodynamic non-linear drag force, and with excessive noise in the measurements. We show that SciMED is sufficiently robust to discover the correct physically meaningful symbolic expressions from the data, and demonstrate how the integration of domain knowledge enhances its performance. Our results indicate better performance on these tasks than the state-of-the-art SR software packages , even in cases where no knowledge is integrated. Moreover, we demonstrate how SciMED can alert the user about possible missing features, unlike the majority of current SR systems.
%G en
%J Scientific Reports
%A Keren, Liron Simon
%A Liberzon, Alex
%A Lazebnik, Teddy
%D 2023-01-23

%0 Conference Paper
%T Contemporary Symbolic Regression Methods and their Relative Performance
%I arXiv
%U http://arxiv.org/abs/2107.14351
%X Many promising approaches to symbolic regression have been presented in recent years, yet progress in the ﬁeld continues to suffer from a lack of uniform, robust, and transparent benchmarking standards. In this paper, we address this shortcoming by introducing an open-source, reproducible benchmarking platform for symbolic regression. We assess 14 symbolic regression methods and 7 machine learning methods on a set of 252 diverse regression problems. Our assessment includes both real-world datasets with no known model form as well as ground-truth benchmark problems, including physics equations and systems of ordinary differential equations. For the real-world datasets, we benchmark the ability of each method to learn models with low error and low complexity relative to state-of-the-art machine learning methods. For the synthetic problems, we assess each method’s ability to ﬁnd exact solutions in the presence of varying levels of noise. Under these controlled experiments, we conclude that the best performing methods for real-world regression combine genetic algorithms with parameter estimation and/or semantic search drivers. When tasked with recovering exact equations in the presence of noise, we ﬁnd that deep learning and genetic algorithm-based approaches perform similarly. We provide a detailed guide to reproducing this experiment and contributing new methods, and encourage other researchers to collaborate with us on a common and living symbolic regression benchmark.
%G en
%B NeurIPS 2021
%A La Cava, William
%A Orzechowski, Patryk
%A Burlacu, Bogdan
%A de França, Fabrício Olivetti
%A Virgolin, Marco
%A Jin, Ying
%A Kommenda, Michael
%A Moore, Jason H.
%D 2021-07-29

%0 Journal Article
%T Rediscovering orbital mechanics with machine learning
%U http://arxiv.org/abs/2202.02306
%X We present an approach for using machine learning to automatically discover the governing equations and hidden properties of real physical systems from observations. We train a “graph neural network” to simulate the dynamics of our solar system’s Sun, planets, and large moons from 30 years of trajectory data. We then use symbolic regression to discover an analytical expression for the force law implicitly learned by the neural network, which our results showed is equivalent to Newton’s law of gravitation. The key assumptions that were required were translational and rotational equivariance, and Newton’s second and third laws of motion. Our approach correctly discovered the form of the symbolic force law. Furthermore, our approach did not require any assumptions about the masses of planets and moons or physical constants. They, too, were accurately inferred through our methods. Though, of course, the classical law of gravitation has been known since Isaac Newton, our result serves as a validation that our method can discover unknown laws and hidden properties from observed data. More broadly this work represents a key step toward realizing the potential of machine learning for accelerating scientiﬁc discovery.
%G en
%J Machine Learning: Science and Technology
%A Lemos, Pablo
%A Jeffrey, Niall
%A Cranmer, Miles
%A Ho, Shirley
%A Battaglia, Peter
%D 2022-02-04
%K Astrophysics - Earth and Planetary Astrophysics

%0 Conference Paper
%T Transformer-based Planning for Symbolic Regression
%X Symbolic regression (SR) is a challenging task in machine learning that involves finding a mathematical expression for a function based on its values. Recent advancements in SR have demonstrated the effectiveness of pre-trained transformer models in generating equations as sequences, leveraging large-scale pre-training on synthetic datasets and offering notable advantages in terms of inference time over classical Genetic Programming (GP) methods. However, these models primarily rely on supervised pre-training objectives borrowed from text generation and overlook equation discovery goals like accuracy and complexity. To address this, we propose TPSR, a Transformer-based Planning strategy for Symbolic Regression that incorporates Monte Carlo Tree Search planning algorithm into the transformer decoding process. Unlike conventional decoding strategies, TPSR enables the integration of non-differentiable equation verification feedback, such as fitting accuracy and complexity, as external sources of knowledge into the transformer equation generation process. Extensive experiments on various datasets show that our approach outperforms state-of-the-art methods, enhancing the model’s fitting-complexity trade-off, extrapolation abilities, and robustness to noise 1 .
%G en
%B NeurIPS 2023
%A Shojaee, Parshin
%A Meidani, Kazem
%A Farimani, Amir Barati
%A Reddy, Chandan K
%D 2023

%0 Conference Paper
%T End-to-end Symbolic Regression with Transformers
%X Symbolic regression, the task of predicting the mathematical expression of a function from the observation of its values, is a difﬁcult task which usually involves a two-step procedure: predicting the "skeleton" of the expression up to the choice of numerical constants, then ﬁtting the constants by optimizing a non-convex loss function. The dominant approach is genetic programming, which evolves candidates by iterating this subroutine a large number of times. Neural networks have recently been tasked to predict the correct skeleton in a single try, but remain much less powerful.
%G en
%B NeurIPS 2022
%A Kamienny, Pierre-Alexandre
%A Lample, Guillaume
%A Charton, François
%D 2022

%0 Conference Paper
%T Deep Symbolic Regression for Recurrent Sequences
%I arXiv
%U http://arxiv.org/abs/2201.04600
%X Symbolic regression, i.e. predicting a function from the observation of its values, is well-known to be a challenging task. In this paper, we train Transformers to infer the function or recurrence relation underlying sequences of integers or floats, a typical task in human IQ tests which has hardly been tackled in the machine learning literature. We evaluate our integer model on a subset of OEIS sequences, and show that it outperforms built-in Mathematica functions for recurrence prediction. We also demonstrate that our float model is able to yield informative approximations of out-of-vocabulary functions and constants, e.g. $\operatorname{bessel0}(x)\approx \frac{\sin(x)+\cos(x)}{\sqrt{\pi x}}$ and $1.644934\approx \pi^2/6$. An interactive demonstration of our models is provided at https://symbolicregression.metademolab.com.
%G en
%B ICML 2022
%A d'Ascoli, Stéphane
%A Kamienny, Pierre-Alexandre
%A Lample, Guillaume
%A Charton, François
%D 2022-06-28
%K Computer Science - Machine Learning

%0 Journal Article
%T Class Symbolic Regression: Gotta Fit ’Em All
%V 969
%N 2
%P L26
%U https://iopscience.iop.org/article/10.3847/2041-8213/ad5970
%X We introduce “Class Symbolic Regression” (Class SR), the first framework for automatically finding a single analytical functional form that accurately fits multiple data sets—each realization being governed by its own (possibly) unique set of fitting parameters. This hierarchical framework leverages the common constraint that all the members of a single class of physical phenomena follow a common governing law. Our approach extends the capabilities of our earlier Physical Symbolic Optimization (Φ-SO) framework for symbolic regression, which integrates dimensional analysis constraints and deep reinforcement learning for unsupervised symbolic analytical function discovery from data. Additionally, we introduce the first Class SR benchmark, comprising a series of synthetic physical challenges specifically designed to evaluate such algorithms. We demonstrate the efficacy of our novel approach by applying it to these benchmark challenges and showcase its practical utility for astrophysics by successfully extracting an analytic galaxy potential from a set of simulated orbits approximating stellar streams.
%G en
%J The Astrophysical Journal Letters
%A Tenachi, Wassim
%A Ibata, Rodrigo
%A François, Thibaut L.
%A Diakogiannis, Foivos I.
%D 2024-07-01

%0 Conference Paper
%T Deep Learning for Symbolic Mathematics
%I arXiv
%U http://arxiv.org/abs/1912.01412
%X Neural networks have a reputation for being better at solving statistical or approximate problems than at performing calculations or working with symbolic data. In this paper, we show that they can be surprisingly good at more elaborated tasks in mathematics, such as symbolic integration and solving differential equations. We propose a syntax for representing mathematical problems, and methods for generating large datasets that can be used to train sequence-to-sequence models. We achieve results that outperform commercial Computer Algebra Systems such as Matlab or Mathematica.
%G en
%B ICLR 2020
%A Lample, Guillaume
%A Charton, François
%D 2019-12-02
%K Computer Science - Machine Learning
Computer Science - Symbolic Computation

%0 Journal Article
%T SymPy: symbolic computing in Python
%V 3
%P e103
%* http://creativecommons.org/licenses/by/4.0/
%U https://peerj.com/articles/cs-103
%X SymPy is an open source computer algebra system written in pure Python. It is built with a focus on extensibility and ease of use, through both interactive and programmatic applications. These characteristics have led SymPy to become a popular symbolic library for the scientific Python ecosystem. This paper presents the architecture of SymPy, a description of its features, and a discussion of select submodules. The supplementary material provide additional examples and further outline details of the architecture and features of SymPy.
%G en
%J PeerJ Computer Science
%A Meurer, Aaron
%A Smith, Christopher P.
%A Paprocki, Mateusz
%A Čertík, Ondřej
%A Kirpichev, Sergey B.
%A Rocklin, Matthew
%A Kumar, AMiT
%A Ivanov, Sergiu
%A Moore, Jason K.
%A Singh, Sartaj
%A Rathnayake, Thilina
%A Vig, Sean
%A Granger, Brian E.
%A Muller, Richard P.
%A Bonazzi, Francesco
%A Gupta, Harsh
%A Vats, Shivam
%A Johansson, Fredrik
%A Pedregosa, Fabian
%A Curry, Matthew J.
%A Terrel, Andy R.
%A Roučka, Štěpán
%A Saboo, Ashutosh
%A Fernando, Isuru
%A Kulal, Sumith
%A Cimrman, Robert
%A Scopatz, Anthony
%D 2017-01-02

%0 Conference Paper
%T A Seq2Seq approach to Symbolic Regression
%X Deep neural networks have proved to be powerful function approximators. The large hypothesis space they implicitly model allows them to ﬁt very complicated black-box functions to the training data. However, often the data generating process is characterized by a concise and relatively simple functional form. This is especially true in natural sciences, where elegant physical laws govern the behaviour of the quantities of interest. In this work, we address this dichotomy from the perspective of Symbolic Regression (SR). In particular, we apply a fully-convolutional seq2seq model to map numerical data to the corresponding symbolic equations. We demonstrate the effectiveness of our approach on a large set of mathematical expressions by providing both a qualitative and a quantitative analysis of our results. Additionally, we release our new equation-generator Python library in order to facilitate benchmarking and stimulate new research on SR1.
%G en
%B NeurIPS 2020
%A Biggio, Luca
%A Bendinelli, Tommaso
%A Lucchi, Aurelien
%A Parascandolo, Giambattista
%D 2020

%0 Journal Article
%T Is the machine smarter than the theorist: Deriving formulas for particle kinematics with symbolic regression
%V 107
%N 5
%P 055018
%U https://link.aps.org/doi/10.1103/PhysRevD.107.055018
%G en
%J Physical Review D
%A Dong, Zhongtian
%A Kong, Kyoungchul
%A Matchev, Konstantin T.
%A Matcheva, Katia
%D 2023-3-13

%0 Journal Article
%T Symbolic machine learning improved MCFT model for punching shear resistance of FRP-reinforced concrete slabs
%V 69
%P 106257
%J Journal of Building Engineering
%A Liang, Shixue
%A Shen, Yuanxie
%A Gao, Xiangling
%A Cai, Yiqing
%A Fei, Zhengyu
%D 2023

%0 Journal Article
%T Axial compressive capacity prediction and optimal design of circular UHPC-filled steel tube based on Hybrid Symbolic Regression - Neural Network model
%V 68
%G en-US
%J STRUCTURES
%A Ren, Zhigang
%A Wang, Dian
%A Kondo, Gen
%D 2024-10

%0 Journal Article
%T Artificial intelligence to deep learning: machine intelligence approach for drug discovery
%V 25
%N 3
%P 1315-1360
%U https://link.springer.com/10.1007/s11030-021-10217-3
%X Drug designing and development is an important area of research for pharmaceutical companies and chemical scientists. However, low efficacy, off-target delivery, time consumption, and high cost impose a hurdle and challenges that impact drug design and discovery. Further, complex and big data from genomics, proteomics, microarray data, and clinical trials also impose an obstacle in the drug discovery pipeline. Artificial intelligence and machine learning technology play a crucial role in drug discovery and development. In other words, artificial neural networks and deep learning algorithms have modernized the area. Machine learning and deep learning algorithms have been implemented in several drug discovery processes such as peptide synthesis, structure-based virtual screening, ligand-based virtual screening, toxicity prediction, drug monitoring and release, pharmacophore modeling, quantitative structure–activity relationship, drug repositioning, polypharmacology, and physiochemical activity. Evidence from the past strengthens the implementation of artificial intelligence and deep learning in this field. Moreover, novel data mining, curation, and management techniques provided critical support to recently developed modeling algorithms. In summary, artificial intelligence and deep learning advancements provide an excellent opportunity for rational drug design and discovery process, which will eventually impact mankind.
%G en
%J Molecular Diversity
%A Gupta, Rohan
%A Srivastava, Devesh
%A Sahu, Mehar
%A Tiwari, Swati
%A Ambasta, Rashmi K.
%A Kumar, Pravir
%D 08/2021

%0 Journal Article
%T Discovery of Physically Interpretable Wave Equations
%U https://link.springer.com/10.1007/s10712-024-09857-5
%X Using symbolic regression to discover physical laws from observed data is an emerging field. In previous work, we combined genetic algorithm (GA) and machine learning to present a data-driven method for discovering a wave equation. Although it managed to utilize the data to discover the two-dimensional (x, z) acoustic constant-density wave equation utt = v2(uxx + uzz) (subscripts of the wavefield, u, are second derivatives in time and space) in a homogeneous medium, it did not provide the complete equation form, where the velocity term is represented by a coefficient rather than directly given by v2. In this work, we redesign the framework, encoding both velocity information and candidate functional terms simultaneously. Thus, we use GA to simultaneously evolve the candidate functional and coefficient terms in the library. Also, we consider here the physics rationality and interpretability in the randomly generated potential wave equations, by ensuring that both-hand sides of the equation maintain balance in their physical units. We demonstrate this redesigned framework using the acoustic wave equation as an example, showing its ability to produce physically reasonable expressions of wave equations from noisy and sparsely observed data in both homogeneous and inhomogeneous media. Also, we demonstrate that our method can effectively discover wave equations from a more realistic observation scenario.
%G en
%J Surveys in Geophysics
%A Cheng, Shijun
%A Alkhalifah, Tariq
%D 2024-09-26

%0 Journal Article
%T Deep Learning and Symbolic Regression for Discovering Parametric Equations
%P 1-13
%* https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html
%U https://ieeexplore.ieee.org/document/10253952/
%X Symbolic regression is a machine learning technique that can learn the equations governing data and thus has the potential to transform scientific discovery. However, symbolic regression is still limited in the complexity and dimensionality of the systems that it can analyze. Deep learning, on the other hand, has transformed machine learning in its ability to analyze extremely complex and high-dimensional datasets. We propose a neural network architecture to extend symbolic regression to parametric systems where some coefficient may vary, but the structure of the underlying governing equation remains constant. We demonstrate our method on various analytic expressions and partial differential equations (PDEs) with varying coefficients and show that it extrapolates well outside of the training domain. The proposed neural-network-based architecture can also be enhanced by integrating with other deep learning architectures such that it can analyze high-dimensional data while being trained end-to-end. To this end, we demonstrate the scalability of our architecture by incorporating a convolutional encoder to analyze 1-D images of varying spring systems.
%G en
%J IEEE Transactions on Neural Networks and Learning Systems
%A Zhang, Michael
%A Kim, Samuel
%A Lu, Peter Y.
%A Soljačić, Marin
%D 2023

%0 Generic
%T Rethinking Symbolic Regression Datasets and Benchmarks for Scientific Discovery
%I arXiv
%U http://arxiv.org/abs/2206.10540
%X This paper revisits datasets and evaluation criteria for Symbolic Regression (SR), specifically focused on its potential for scientific discovery. Focused on a set of formulas used in the existing datasets based on Feynman Lectures on Physics, we recreate 120 datasets to discuss the performance of symbolic regression for scientific discovery (SRSD). For each of the 120 SRSD datasets, we carefully review the properties of the formula and its variables to design reasonably realistic sampling ranges of values so that our new SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an SR method can (re)discover physical laws from such datasets. We also create another 120 datasets that contain dummy variables to examine whether SR methods can choose necessary variables only. Besides, we propose to use normalized edit distances (NED) between a predicted equation and the true equation trees for addressing a critical issue that existing SR metrics are either binary or errors between the target values and an SR model's predicted values for a given input. We conduct benchmark experiments on our new SRSD datasets using various representative SR methods. The experimental results show that we provide a more realistic performance evaluation, and our user study shows that the NED correlates with human judges significantly more than an existing SR metric. We publish repositories of our code and 240 SRSD datasets.
%G en
%A Matsubara, Yoshitomo
%A Chiba, Naoya
%A Igarashi, Ryo
%A Ushiku, Yoshitaka
%D 2024-03-05
%K Computer Science - Artificial Intelligence
Computer Science - Machine Learning
Computer Science - Symbolic Computation
Computer Science - Neural and Evolutionary Computing

%0 Journal Article
%T Simple descriptor derived from symbolic regression accelerating the discovery of new perovskite catalysts
%V 11
%N 1
%P 3513
%U https://www.nature.com/articles/s41467-020-17263-9
%X Abstract
            
              Symbolic regression (SR) is an approach of interpretable machine learning for building mathematical formulas that best fit certain datasets. In this work, SR is used to guide the design of new oxide perovskite catalysts with improved oxygen evolution reaction (OER) activities. A simple descriptor,
              μ
              /
              t
              , where
              μ
              and
              t
              are the octahedral and tolerance factors, respectively, is identified, which accelerates the discovery of a series of new oxide perovskite catalysts with improved OER activity. We successfully synthesise five new oxide perovskites and characterise their OER activities. Remarkably, four of them, Cs
              0.4
              La
              0.6
              Mn
              0.25
              Co
              0.75
              O
              3
              , Cs
              0.3
              La
              0.7
              NiO
              3
              , SrNi
              0.75
              Co
              0.25
              O
              3
              , and Sr
              0.25
              Ba
              0.75
              NiO
              3
              , are among the oxide perovskite catalysts with the highest intrinsic activities. Our results demonstrate the potential of SR for accelerating the data-driven design and discovery of new materials with improved properties.
%G en
%J Nature Communications
%A Weng, Baicheng
%A Song, Zhilong
%A Zhu, Rilong
%A Yan, Qingyu
%A Sun, Qingde
%A Grice, Corey G.
%A Yan, Yanfa
%A Yin, Wan-Jian
%D 2020-07-14

%0 Journal Article
%T Symbolic regression in materials science
%V 9
%N 3
%P 793-805
%U http://link.springer.com/10.1557/mrc.2019.85
%X The authors showcase the potential of symbolic regression as an analytic method for use in materials research. First, the authors brieﬂy describe the current state-of-the-art method, genetic programming-based symbolic regression (GPSR), and recent advances in symbolic regression techniques. Next, the authors discuss industrial applications of symbolic regression and its potential applications in materials science. The authors then present two GPSR use-cases: formulating a transformation kinetics law and showing the learning scheme discovers the well-known Johnson–Mehl–Avrami–Kolmogorov form, and learning the Landau free energy functional form for the displacive tilt transition in perovskite LaNiO3. Finally, the authors propose that symbolic regression techniques should be considered by materials scientists as an alternative to other machine learning-based regression models for learning from data.
%G en
%J MRS Communications
%A Wang, Yiqun
%A Wagner, Nicholas
%A Rondinelli, James M.
%D 09/2019

%0 Journal Article
%T Discovering Mathematical Expressions Through DeepSymNet: A Classification-Based Symbolic Regression Framework
%P 1-15
%* https://creativecommons.org/licenses/by-nc-nd/4.0/
%U https://ieeexplore.ieee.org/document/10327762/
%X Symbolic regression (SR) is the process of finding an unknown mathematical expression given the input and output and has important applications in interpretable machine learning and knowledge discovery. The major difficulty of SR is that finding the expression structure is an NP-hard problem, which makes the entire process time-consuming. In this study, the solution of expression structures was regarded as a classification problem and solved by supervised learning such that SR can be solved quickly by using the solving experience. Techniques for classification tasks, such as equivalent label merging and sample balance, were used to enhance the robustness of the algorithm. We proposed a symbolic network called DeepSymNet to represent symbolic expressions to improve the performance of the algorithm. DeepSymNet has been proven to have a strong representation ability with a shorter label compared to the current popular representation methods, reducing the search space when predicting. Moreover, DeepSymNet conveniently decomposes SR into two smaller subproblems, which makes solving the problem easier. The proposed algorithm was tested on artificially generated expressions and public datasets and compared with other algorithms. The results demonstrate the effectiveness of the proposed algorithm.
%G en
%J IEEE Transactions on Neural Networks and Learning Systems
%A Wu, Min
%A Li, Weijun
%A Yu, Lina
%A Sun, Linjun
%A Liu, Jingyi
%A Li, Wenqiang
%D 2024

%0 Conference Paper
%T DEEP SYMBOLIC REGRESSION: RECOVERING MATHEMATICAL EXPRESSIONS FROM DATA VIA RISK-SEEKING POLICY GRADIENTS
%X Discovering the underlying mathematical expressions describing a dataset is a core challenge for artiﬁcial intelligence. This is the problem of symbolic regression. Despite recent advances in training neural networks to solve complex tasks, deep learning approaches to symbolic regression are underexplored. We propose a framework that leverages deep learning for symbolic regression via a simple idea: use a large model to search the space of small models. Speciﬁcally, we use a recurrent neural network to emit a distribution over tractable mathematical expressions and employ a novel risk-seeking policy gradient to train the network to generate better-ﬁtting expressions. Our algorithm outperforms several baseline methods (including Eureqa, the gold standard for symbolic regression) in its ability to exactly recover symbolic expressions on a series of benchmark problems, both with and without added noise. More broadly, our contributions include a framework that can be applied to optimize hierarchical, variable-length objects under a blackbox performance metric, with the ability to incorporate constraints in situ, and a risk-seeking policy gradient formulation that optimizes for best-case performance instead of expected performance.
%G en
%B ICLR 2021
%A Petersen, Brenden K
%A Larma, Mikel Landajuela
%A Mundhenk, T Nathan
%A Santiago, Claudio P
%A Kim, Soo K
%A Kim, Joanne T
%D 2021
%K Computer Science - Machine Learning
Statistics - Machine Learning

%0 Conference Paper
%T Deep Generative Symbolic Regression
%I arXiv
%U http://arxiv.org/abs/2401.00282
%X Symbolic regression (SR) aims to discover concise closed-form mathematical equations from data, a task fundamental to scientific discovery. However, the problem is highly challenging because closed-form equations lie in a complex combinatorial search space. Existing methods, ranging from heuristic search to reinforcement learning, fail to scale with the number of input variables. We make the observation that closed-form equations often have structural characteristics and invariances (e.g., the commutative law) that could be further exploited to build more effective symbolic regression solutions. Motivated by this observation, our key contribution is to leverage pre-trained deep generative models to capture the intrinsic regularities of equations, thereby providing a solid foundation for subsequent optimization steps. We show that our novel formalism unifies several prominent approaches of symbolic regression and offers a new perspective to justify and improve on the previous ad hoc designs, such as the usage of cross-entropy loss during pre-training. Specifically, we propose an instantiation of our framework, Deep Generative Symbolic Regression (DGSR). In our experiments, we show that DGSR achieves a higher recovery rate of true equations in the setting of a larger number of input variables, and it is more computationally efficient at inference time than state-of-the-art RL symbolic regression solutions.
%G en
%B ICLR 2023
%A Holt, Samuel
%A Qian, Zhaozhi
%A Schaar, Mihaela van der
%D 2023-12-30
%K Computer Science - Machine Learning

%0 Journal Article
%T Interpretable machine learning for science with PySR and SymbolicRegression. jl
%J arXiv preprint arXiv:2305.01582
%A Cranmer, Miles
%D 2023

%0 Journal Article
%T Physics-informed learning of governing equations from scarce data
%V 12
%N 1
%P 6136
%U https://www.nature.com/articles/s41467-021-26434-1
%X Abstract
            Harnessing data to discover the underlying governing laws or equations that describe the behavior of complex physical systems can significantly advance our modeling, simulation and understanding of such systems in various science and engineering disciplines. This work introduces a novel approach called physics-informed neural network with sparse regression to discover governing partial differential equations from scarce and noisy data for nonlinear spatiotemporal systems. In particular, this discovery approach seamlessly integrates the strengths of deep neural networks for rich representation learning, physics embedding, automatic differentiation and sparse regression to approximate the solution of system variables, compute essential derivatives, as well as identify the key derivative terms and parameters that form the structure and explicit expression of the equations. The efficacy and robustness of this method are demonstrated, both numerically and experimentally, on discovering a variety of partial differential equation systems with different levels of data scarcity and noise accounting for different initial/boundary conditions. The resulting computational framework shows the potential for closed-form model discovery in practical applications where large and accurate datasets are intractable to capture.
%G en
%J Nature Communications
%A Chen, Zhao
%A Liu, Yang
%A Sun, Hao
%D 2021-10-21

%0 Generic
%T Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks
%I arXiv
%U http://arxiv.org/abs/1810.00825
%X Many machine learning tasks such as multiple instance learning, 3D shape recognition and fewshot image classiﬁcation are deﬁned on sets of instances. Since solutions to such problems do not depend on the order of elements of the set, models used to address them should be permutation invariant. We present an attention-based neural network module, the Set Transformer, speciﬁcally designed to model interactions among elements in the input set. The model consists of an encoder and a decoder, both of which rely on attention mechanisms. In an effort to reduce computational complexity, we introduce an attention scheme inspired by inducing point methods from sparse Gaussian process literature. It reduces computation time of self-attention from quadratic to linear in the number of elements in the set. We show that our model is theoretically attractive and we evaluate it on a range of tasks, demonstrating increased performance compared to recent methods for set-structured data.
%G en
%A Lee, Juho
%A Lee, Yoonho
%A Kim, Jungtaek
%A Kosiorek, Adam R.
%A Choi, Seungjin
%A Teh, Yee Whye
%D 2019-05-26
%K Computer Science - Machine Learning
Statistics - Machine Learning

%0 Generic
%T Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
%I arXiv
%U http://arxiv.org/abs/1910.10683
%X Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new ``Colossal Clean Crawled Corpus'', we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.
%G en
%A Raffel, Colin
%A Shazeer, Noam
%A Roberts, Adam
%A Lee, Katherine
%A Narang, Sharan
%A Matena, Michael
%A Zhou, Yanqi
%A Li, Wei
%A Liu, Peter J.
%D 2023-09-19
%K Computer Science - Computation and Language
Computer Science - Machine Learning
Statistics - Machine Learning

%0 Generic
%T Neural Symbolic Regression that Scales
%I arXiv
%U http://arxiv.org/abs/2106.06427
%X Symbolic equations are at the core of scientiﬁc discovery. The task of discovering the underlying equation from a set of input-output pairs is called symbolic regression. Traditionally, symbolic regression methods use hand-designed strategies that do not improve with experience. In this paper, we introduce the ﬁrst symbolic regression method that leverages large scale pre-training. We procedurally generate an unbounded set of equations, and simultaneously pre-train a Transformer to predict the symbolic equation from a corresponding set of input-output-pairs. At test time, we query the model on a new set of points and use its output to guide the search for the equation. We show empirically that this approach can re-discover a set of well-known physical equations, and that it improves over time with more data and compute.
%G en
%A Biggio, Luca
%A Bendinelli, Tommaso
%A Neitz, Alexander
%A Lucchi, Aurelien
%A Parascandolo, Giambattista
%D 2021-06-11
%K Computer Science - Machine Learning

%0 Generic
%T SymbolicGPT: A Generative Transformer Model for Symbolic Regression
%I arXiv
%U http://arxiv.org/abs/2106.14131
%X Symbolic regression is the task of identifying a mathematical expression that best ﬁts a provided dataset of input and output values. Due to the richness of the space of mathematical expressions, symbolic regression is generally a challenging problem. While conventional approaches based on genetic evolution algorithms have been used for decades, deep learning-based methods are relatively new and an active research area. In this work, we present SymbolicGPT, a novel transformer-based language model for symbolic regression3. This model exploits the advantages of probabilistic language models like GPT, including strength in performance and ﬂexibility. Through comprehensive experiments, we show that our model performs strongly compared to competing models with respect to the accuracy, running time, and data efﬁciency.
%G en
%A Valipour, Mojtaba
%A You, Bowen
%A Panju, Maysum
%A Ghodsi, Ali
%D 2021-06-27
%K Computer Science - Computation and Language
Computer Science - Machine Learning
Computer Science - Symbolic Computation

%0 Journal Article
%T Deep Symbolic Regression for Physics Guided by Units Constraints: Toward the Automated Discovery of Physical Laws
%V 959
%N 2
%P 99
%U https://iopscience.iop.org/article/10.3847/1538-4357/ad014c
%X Symbolic regression (SR) is the study of algorithms that automate the search for analytic expressions that ﬁt data. While recent advances in deep learning have generated renewed interest in such approaches, the development of SR methods has not been focused on physics, where we have important additional constraints due to the units associated with our data. Here we present Φ-SO, a physical symbolic optimization framework for recovering analytical symbolic expressions from physics data using deep reinforcement learning techniques by learning units constraints. Our system is built, from the ground up, to propose solutions where the physical units are consistent by construction. This is useful not only in eliminating physically impossible solutions but also because the grammatical rules of dimensional analysis enormously restrict the freedom of the equation generator, thus vastly improving performance. The algorithm can be used to ﬁt noiseless data, which can be useful, for instance, when attempting to derive an analytical property of a physical model, and it can also be used to obtain analytical approximations of noisy data. We test our machinery on a standard benchmark of equations from the Feynman Lectures on Physics and other physics textbooks, achieving state-of-the-art performance in the presence of noise (exceeding 0.1%) and show that it is robust even in the presence of substantial (10%) noise. We showcase its abilities on a panel of examples from astrophysics.
%G en
%J The Astrophysical Journal
%A Tenachi, Wassim
%A Ibata, Rodrigo
%A Diakogiannis, Foivos I.
%D 2023-12-01

%0 Journal Article
%T SRBench++: Principled Benchmarking of Symbolic Regression With Domain-Expert Interpretation
%P 1-1
%* https://creativecommons.org/licenses/by/4.0/legalcode
%U https://ieeexplore.ieee.org/document/10586218/
%X Symbolic regression searches for analytic expressions that accurately describe studied phenomena. The main promise of this approach is that it may return an interpretable model that can be insightful to users, while maintaining high accuracy. The current standard for benchmarking these algorithms is SRBench, which evaluates methods on hundreds of datasets that are a mix of real-world and simulated processes spanning multiple domains. At present, the ability of SRBench to evaluate interpretability is limited to measuring the size of expressions on real-world data, and the exactness of model forms on synthetic data. In practice, model size is only one of many factors used by subject experts to determine how interpretable a model truly is. Furthermore, SRBench does not characterize algorithm performance on speciﬁc, challenging sub-tasks of regression such as feature selection and evasion of local minima. In this work, we propose and evaluate an approach to benchmarking SR algorithms that addresses these limitations of SRBench by 1) incorporating expert evaluations of interpretability on a domain-speciﬁc task, and 2) evaluating algorithms over distinct properties of data science tasks. We evaluate 12 modern symbolic regression algorithms on these benchmarks and present an in-depth analysis of the results, discuss current challenges of symbolic regression algorithms and highlight possible improvements for the benchmark itself.
%G en
%J IEEE Transactions on Evolutionary Computation
%A De Franca, F. O.
%A Virgolin, M.
%A Kommenda, M.
%A Majumder, M. S.
%A Cranmer, M.
%A Espada, G.
%A Ingelse, L.
%A Fonseca, A.
%A Landajuela, M.
%A Petersen, B.
%A Glatt, R.
%A Mundhenk, N.
%A Lee, C. S.
%A Hochhalter, J. D.
%A Randall, D. L.
%A Kamienny, P.
%A Zhang, H.
%A Dick, G.
%A Simon, A.
%A Burlacu, B.
%A Kasak, Jaan
%A Machado, Meera
%A Wilstrup, Casper
%A Cavaz, W. G. La
%D 2024

%0 Journal Article
%T Symbolic machine learning improved MCFT model for punching shear resistance of FRP-reinforced concrete slabs
%V 69
%P 106257
%U https://linkinghub.elsevier.com/retrieve/pii/S2352710223004369
%X Fiber reinforced polymer (FRP)-reinforced concrete slabs, an extension of reinforced concrete (RC) slabs leveraged for resisting environment corrosion, are susceptible to punching shear failure due to the lower elasticity modulus of FRP reinforcement. To estimate the punching shear resistance accurately, there are two types of models (e.g., white box and black-box models) proposed based on theoretical derivations and machine learning methods. However, these two types of models are considered as independent of each other. In this study, a hybrid model (e.g., grey-box model) derived from modified compression field theory (MCFT) is proposed by this paper, in which the performance is improved by a machine-learning-aided approach (genetic programming). In order to exploit the performance of machine learning, a database containing 154 experimental data is established and used for fitting the correction equations. Iterating the population containing 300 tree-based individuals in 300 times, a correction equation with simple format is obtained, which performs well in performance improvement of the basic model derived from MCFT. Herein, the influential factors involved in the correction equation comply with the sorting in order of the importance quantified by extreme gradient boosting (XGBoost) and shapley additive explanation (SHAP). Combining the correction equation with the basic model derived from MCFT, a symbolic regression MCFT (SR-MCFT) model is established, which performs better prediction performance than other five empirical models.
%G en
%J Journal of Building Engineering
%A Liang, Shixue
%A Shen, Yuanxie
%A Gao, Xiangling
%A Cai, Yiqing
%A Fei, Zhengyu
%D 06/2023

%0 Conference Paper
%T A Unified Framework for Deep Symbolic Regression
%X The last few years have witnessed a surge in methods for symbolic regression, from advances in traditional evolutionary approaches to novel deep learning-based systems. Individual works typically focus on advancing the state-of-the-art for one particular class of solution strategies, and there have been few attempts to investigate the beneﬁts of hybridizing or integrating multiple strategies. In this work, we identify ﬁve classes of symbolic regression solution strategies—recursive problem simpliﬁcation, neural-guided search, large-scale pre-training, genetic programming, and linear models—and propose a strategy to hybridize them into a single modular, uniﬁed symbolic regression framework. Based on empirical evaluation using SRBench, a new community tool for benchmarking symbolic regression methods, our uniﬁed framework achieves state-of-the-art performance in its ability to (1) symbolically recover analytical expressions, (2) ﬁt datasets with high accuracy, and (3) balance accuracy-complexity trade-offs, across 252 ground-truth and black-box benchmark problems, in both noiseless settings and across various noise levels. Finally, we provide practical use case-based guidance for constructing hybrid symbolic regression algorithms, supported by extensive, combinatorial ablation studies.
%G en
%B NeurIPS 2022
%A Landajuela, Mikel
%A Lee, Chak Shing
%A Yang, Jiachen
%A Glatt, Ruben
%A Santiago, Claudio
%A Mundhenk, T Nathan
%A Aravena, Ignacio
%A Mulcahy, Garrett
%A Petersen, Brenden
%D 2022

%0 Journal Article
%T Artificial Intelligence in Physical Sciences: Symbolic Regression Trends and Perspectives
%V 30
%N 6
%P 3845-3865
%U https://link.springer.com/10.1007/s11831-023-09922-z
%X Symbolic regression (SR) is a machine learning-based regression method based on genetic programming principles that integrates techniques and processes from heterogeneous scientific fields and is capable of providing analytical equations purely from data. This remarkable characteristic diminishes the need to incorporate prior knowledge about the investigated system. SR can spot profound and elucidate ambiguous relations that can be generalizable, applicable, explainable and span over most scientific, technological, economical, and social principles. In this review, current state of the art is documented, technical and physical characteristics of SR are presented, the available programming techniques are investigated, fields of application are explored, and future perspectives are discussed.
%G en
%J Archives of Computational Methods in Engineering
%A Angelis, Dimitrios
%A Sofos, Filippos
%A Karakasidis, Theodoros E.
%D 07/2023

%0 Journal Article
%T AI Feynman: A physics-inspired method for symbolic regression
%V 6
%N 16
%P eaay2631
%U https://www.science.org/doi/10.1126/sciadv.aay2631
%X 【AIFeynman，曾经的GOAT】
Our physics-inspired algorithm for symbolic regression is able to discover complex physics equations from mere tables of numbers.
              A core challenge for both physics and artificial intelligence (AI) is symbolic regression: finding a symbolic expression that matches data from an unknown function. Although this problem is likely to be NP-hard in principle, functions of practical interest often exhibit symmetries, separability, compositionality, and other simplifying properties. In this spirit, we develop a recursive multidimensional symbolic regression algorithm that combines neural network fitting with a suite of physics-inspired techniques. We apply it to 100 equations from the
              Feynman Lectures on Physics
              , and it discovers all of them, while previous publicly available software cracks only 71; for a more difficult physics-based test set, we improve the state-of-the-art success rate from 15 to 90%.
%G en
%J Science Advances
%A Udrescu, Silviu-Marian
%A Tegmark, Max
%D 2020-04-17

%0 Journal Article
%T SymFormer: End-to-End Symbolic Regression Using Transformer-Based Architecture
%V 12
%P 37840-37849
%* https://creativecommons.org/licenses/by/4.0/legalcode
%U https://ieeexplore.ieee.org/document/10462113/
%X Many real-world systems can be naturally described by mathematical formulas. The task of automatically constructing formulas to fit observed data is called symbolic regression. Evolutionary methods such as genetic programming have been commonly used to solve symbolic regression tasks, but they have significant drawbacks, such as high computational complexity. Recently, neural networks have been applied to symbolic regression, among which the transformer-based methods seem to be most promising. After training a transformer on a large number of formulas, the actual inference, i.e., finding a formula for new, unseen data, is very fast (in the order of seconds). This is considerably faster than state-ofthe-art evolutionary methods. The main drawback of transformers is that they generate formulas without numerical constants, which have to be optimized separately, yielding suboptimal results. We propose a transformer-based approach called SymFormer, which predicts the formula by outputting the symbols and the constants simultaneously. This helps to generate formulas that fit the data more accurately. In addition, the constants provided by SymFormer serve as a good starting point for subsequent tuning via gradient descent to further improve the model accuracy. We show on several benchmarks that SymFormer outperforms stateof-the-art methods while having faster inference.
%G en
%J IEEE Access
%A Vastl, Martin
%A Kulhánek, Jonáš
%A Kubalík, Jiří
%A Derner, Erik
%A Babuška, Robert
%D 2024

%0 Journal Article
%T Interpretable scientific discovery with symbolic regression: a review
%V 57
%N 1
%P 2
%U https://link.springer.com/10.1007/s10462-023-10622-0
%X Symbolic regression is emerging as a promising machine learning method for learning succinct underlying interpretable mathematical expressions directly from data. Whereas it has been traditionally tackled with genetic programming, it has recently gained a growing interest in deep learning as a data-driven model discovery tool, achieving significant advances in various application domains ranging from fundamental to applied sciences. In this survey, we present a structured and comprehensive overview of symbolic regression methods, review the adoption of these methods for model discovery in various areas, and assess their effectiveness. We have also grouped state-of-the-art symbolic regression applications in a categorized manner in a living review.
%G en
%J Artificial Intelligence Review
%A Makke, Nour
%A Chawla, Sanjay
%D 01/2024

%0 Journal Article
%T Toward Physically Plausible Data-Driven Models: A Novel Neural Network Approach to Symbolic Regression
%V 11
%P 61481-61501
%* https://creativecommons.org/licenses/by/4.0/legalcode
%U https://ieeexplore.ieee.org/document/10155126/
%X Many real-world systems can be described by mathematical models that are humancomprehensible, easy to analyze and help explain the system’s behavior. Symbolic regression is a method that can automatically generate such models from data. Historically, symbolic regression has been predominantly realized by genetic programming, a method that evolves populations of candidate solutions that are subsequently modified by genetic operators crossover and mutation. However, this approach suffers from several deficiencies: it does not scale well with the number of variables and samples in the training data –models tend to grow in size and complexity without an adequate accuracy gain, and it is hard to fine-tune the model coefficients using just genetic operators. Recently, neural networks have been applied to learn the whole analytic model, i.e., its structure and the coefficients, using gradient-based optimization algorithms. This paper proposes a novel neural network-based symbolic regression method that constructs physically plausible models based on even very small training data sets and prior knowledge about the system. The method employs an adaptive weighting scheme to effectively deal with multiple loss function terms and an epoch-wise learning process to reduce the chance of getting stuck in poor local optima. Furthermore, we propose a parameter-free method for choosing the model with the best interpolation and extrapolation performance out of all the models generated throughout the whole learning process. We experimentally evaluate the approach on four test systems: the TurtleBot 2 mobile robot, the magnetic manipulation system, the equivalent resistance of two resistors in parallel, and the longitudinal force of the anti-lock braking system. The results clearly show the potential of the method to find parsimonious models that comply with the prior knowledge provided.
%G en
%J IEEE Access
%A Kubalík, Jiří
%A Derner, Erik
%A Babuška, Robert
%D 2023

%0 Journal Article
%T A computational framework for physics-informed symbolic regression with straightforward integration of domain knowledge
%V 13
%N 1
%P 1249
%U https://www.nature.com/articles/s41598-023-28328-2
%X Discovering a meaningful symbolic expression that explains experimental data is a fundamental challenge in many scientific fields. We present a novel, open-source computational framework called
              Scientist-Machine Equation Detector
              (SciMED), which integrates scientific discipline wisdom in a scientist-in-the-loop approach, with state-of-the-art symbolic regression (SR) methods. SciMED combines a wrapper selection method, that is based on a genetic algorithm, with automatic machine learning and two levels of SR methods. We test SciMED on five configurations of a settling sphere, with and without aerodynamic non-linear drag force, and with excessive noise in the measurements. We show that SciMED is sufficiently robust to discover the correct physically meaningful symbolic expressions from the data, and demonstrate how the integration of domain knowledge enhances its performance. Our results indicate better performance on these tasks than the state-of-the-art SR software packages , even in cases where no knowledge is integrated. Moreover, we demonstrate how SciMED can alert the user about possible missing features, unlike the majority of current SR systems.
%G en
%J Scientific Reports
%A Keren, Liron Simon
%A Liberzon, Alex
%A Lazebnik, Teddy
%D 2023-01-23

%0 Conference Paper
%T Contemporary Symbolic Regression Methods and their Relative Performance
%I arXiv
%U http://arxiv.org/abs/2107.14351
%X Many promising approaches to symbolic regression have been presented in recent years, yet progress in the ﬁeld continues to suffer from a lack of uniform, robust, and transparent benchmarking standards. In this paper, we address this shortcoming by introducing an open-source, reproducible benchmarking platform for symbolic regression. We assess 14 symbolic regression methods and 7 machine learning methods on a set of 252 diverse regression problems. Our assessment includes both real-world datasets with no known model form as well as ground-truth benchmark problems, including physics equations and systems of ordinary differential equations. For the real-world datasets, we benchmark the ability of each method to learn models with low error and low complexity relative to state-of-the-art machine learning methods. For the synthetic problems, we assess each method’s ability to ﬁnd exact solutions in the presence of varying levels of noise. Under these controlled experiments, we conclude that the best performing methods for real-world regression combine genetic algorithms with parameter estimation and/or semantic search drivers. When tasked with recovering exact equations in the presence of noise, we ﬁnd that deep learning and genetic algorithm-based approaches perform similarly. We provide a detailed guide to reproducing this experiment and contributing new methods, and encourage other researchers to collaborate with us on a common and living symbolic regression benchmark.
%G en
%B NeurIPS 2021
%A La Cava, William
%A Orzechowski, Patryk
%A Burlacu, Bogdan
%A de França, Fabrício Olivetti
%A Virgolin, Marco
%A Jin, Ying
%A Kommenda, Michael
%A Moore, Jason H.
%D 2021-07-29

%0 Journal Article
%T Rediscovering orbital mechanics with machine learning
%U http://arxiv.org/abs/2202.02306
%X We present an approach for using machine learning to automatically discover the governing equations and hidden properties of real physical systems from observations. We train a “graph neural network” to simulate the dynamics of our solar system’s Sun, planets, and large moons from 30 years of trajectory data. We then use symbolic regression to discover an analytical expression for the force law implicitly learned by the neural network, which our results showed is equivalent to Newton’s law of gravitation. The key assumptions that were required were translational and rotational equivariance, and Newton’s second and third laws of motion. Our approach correctly discovered the form of the symbolic force law. Furthermore, our approach did not require any assumptions about the masses of planets and moons or physical constants. They, too, were accurately inferred through our methods. Though, of course, the classical law of gravitation has been known since Isaac Newton, our result serves as a validation that our method can discover unknown laws and hidden properties from observed data. More broadly this work represents a key step toward realizing the potential of machine learning for accelerating scientiﬁc discovery.
%G en
%J Machine Learning: Science and Technology
%A Lemos, Pablo
%A Jeffrey, Niall
%A Cranmer, Miles
%A Ho, Shirley
%A Battaglia, Peter
%D 2022-02-04
%K Astrophysics - Earth and Planetary Astrophysics

%0 Conference Paper
%T Transformer-based Planning for Symbolic Regression
%X Symbolic regression (SR) is a challenging task in machine learning that involves finding a mathematical expression for a function based on its values. Recent advancements in SR have demonstrated the effectiveness of pre-trained transformer models in generating equations as sequences, leveraging large-scale pre-training on synthetic datasets and offering notable advantages in terms of inference time over classical Genetic Programming (GP) methods. However, these models primarily rely on supervised pre-training objectives borrowed from text generation and overlook equation discovery goals like accuracy and complexity. To address this, we propose TPSR, a Transformer-based Planning strategy for Symbolic Regression that incorporates Monte Carlo Tree Search planning algorithm into the transformer decoding process. Unlike conventional decoding strategies, TPSR enables the integration of non-differentiable equation verification feedback, such as fitting accuracy and complexity, as external sources of knowledge into the transformer equation generation process. Extensive experiments on various datasets show that our approach outperforms state-of-the-art methods, enhancing the model’s fitting-complexity trade-off, extrapolation abilities, and robustness to noise 1 .
%G en
%B NeurIPS 2023
%A Shojaee, Parshin
%A Meidani, Kazem
%A Farimani, Amir Barati
%A Reddy, Chandan K
%D 2023

%0 Conference Paper
%T End-to-end Symbolic Regression with Transformers
%X Symbolic regression, the task of predicting the mathematical expression of a function from the observation of its values, is a difﬁcult task which usually involves a two-step procedure: predicting the "skeleton" of the expression up to the choice of numerical constants, then ﬁtting the constants by optimizing a non-convex loss function. The dominant approach is genetic programming, which evolves candidates by iterating this subroutine a large number of times. Neural networks have recently been tasked to predict the correct skeleton in a single try, but remain much less powerful.
%G en
%B NeurIPS 2022
%A Kamienny, Pierre-Alexandre
%A Lample, Guillaume
%A Charton, François
%D 2022

%0 Conference Paper
%T Deep Symbolic Regression for Recurrent Sequences
%I arXiv
%U http://arxiv.org/abs/2201.04600
%X Symbolic regression, i.e. predicting a function from the observation of its values, is well-known to be a challenging task. In this paper, we train Transformers to infer the function or recurrence relation underlying sequences of integers or floats, a typical task in human IQ tests which has hardly been tackled in the machine learning literature. We evaluate our integer model on a subset of OEIS sequences, and show that it outperforms built-in Mathematica functions for recurrence prediction. We also demonstrate that our float model is able to yield informative approximations of out-of-vocabulary functions and constants, e.g. $\operatorname{bessel0}(x)\approx \frac{\sin(x)+\cos(x)}{\sqrt{\pi x}}$ and $1.644934\approx \pi^2/6$. An interactive demonstration of our models is provided at https://symbolicregression.metademolab.com.
%G en
%B ICML 2022
%A d'Ascoli, Stéphane
%A Kamienny, Pierre-Alexandre
%A Lample, Guillaume
%A Charton, François
%D 2022-06-28
%K Computer Science - Machine Learning

%0 Journal Article
%T Class Symbolic Regression: Gotta Fit ’Em All
%V 969
%N 2
%P L26
%U https://iopscience.iop.org/article/10.3847/2041-8213/ad5970
%X We introduce “Class Symbolic Regression” (Class SR), the first framework for automatically finding a single analytical functional form that accurately fits multiple data sets—each realization being governed by its own (possibly) unique set of fitting parameters. This hierarchical framework leverages the common constraint that all the members of a single class of physical phenomena follow a common governing law. Our approach extends the capabilities of our earlier Physical Symbolic Optimization (Φ-SO) framework for symbolic regression, which integrates dimensional analysis constraints and deep reinforcement learning for unsupervised symbolic analytical function discovery from data. Additionally, we introduce the first Class SR benchmark, comprising a series of synthetic physical challenges specifically designed to evaluate such algorithms. We demonstrate the efficacy of our novel approach by applying it to these benchmark challenges and showcase its practical utility for astrophysics by successfully extracting an analytic galaxy potential from a set of simulated orbits approximating stellar streams.
%G en
%J The Astrophysical Journal Letters
%A Tenachi, Wassim
%A Ibata, Rodrigo
%A François, Thibaut L.
%A Diakogiannis, Foivos I.
%D 2024-07-01

%0 Conference Paper
%T Deep Learning for Symbolic Mathematics
%I arXiv
%U http://arxiv.org/abs/1912.01412
%X Neural networks have a reputation for being better at solving statistical or approximate problems than at performing calculations or working with symbolic data. In this paper, we show that they can be surprisingly good at more elaborated tasks in mathematics, such as symbolic integration and solving differential equations. We propose a syntax for representing mathematical problems, and methods for generating large datasets that can be used to train sequence-to-sequence models. We achieve results that outperform commercial Computer Algebra Systems such as Matlab or Mathematica.
%G en
%B ICLR 2020
%A Lample, Guillaume
%A Charton, François
%D 2019-12-02
%K Computer Science - Machine Learning
Computer Science - Symbolic Computation

%0 Journal Article
%T SymPy: symbolic computing in Python
%V 3
%P e103
%* http://creativecommons.org/licenses/by/4.0/
%U https://peerj.com/articles/cs-103
%X SymPy is an open source computer algebra system written in pure Python. It is built with a focus on extensibility and ease of use, through both interactive and programmatic applications. These characteristics have led SymPy to become a popular symbolic library for the scientific Python ecosystem. This paper presents the architecture of SymPy, a description of its features, and a discussion of select submodules. The supplementary material provide additional examples and further outline details of the architecture and features of SymPy.
%G en
%J PeerJ Computer Science
%A Meurer, Aaron
%A Smith, Christopher P.
%A Paprocki, Mateusz
%A Čertík, Ondřej
%A Kirpichev, Sergey B.
%A Rocklin, Matthew
%A Kumar, AMiT
%A Ivanov, Sergiu
%A Moore, Jason K.
%A Singh, Sartaj
%A Rathnayake, Thilina
%A Vig, Sean
%A Granger, Brian E.
%A Muller, Richard P.
%A Bonazzi, Francesco
%A Gupta, Harsh
%A Vats, Shivam
%A Johansson, Fredrik
%A Pedregosa, Fabian
%A Curry, Matthew J.
%A Terrel, Andy R.
%A Roučka, Štěpán
%A Saboo, Ashutosh
%A Fernando, Isuru
%A Kulal, Sumith
%A Cimrman, Robert
%A Scopatz, Anthony
%D 2017-01-02

%0 Conference Paper
%T A Seq2Seq approach to Symbolic Regression
%X Deep neural networks have proved to be powerful function approximators. The large hypothesis space they implicitly model allows them to ﬁt very complicated black-box functions to the training data. However, often the data generating process is characterized by a concise and relatively simple functional form. This is especially true in natural sciences, where elegant physical laws govern the behaviour of the quantities of interest. In this work, we address this dichotomy from the perspective of Symbolic Regression (SR). In particular, we apply a fully-convolutional seq2seq model to map numerical data to the corresponding symbolic equations. We demonstrate the effectiveness of our approach on a large set of mathematical expressions by providing both a qualitative and a quantitative analysis of our results. Additionally, we release our new equation-generator Python library in order to facilitate benchmarking and stimulate new research on SR1.
%G en
%B NeurIPS 2020
%A Biggio, Luca
%A Bendinelli, Tommaso
%A Lucchi, Aurelien
%A Parascandolo, Giambattista
%D 2020

%0 Journal Article
%T Is the machine smarter than the theorist: Deriving formulas for particle kinematics with symbolic regression
%V 107
%N 5
%P 055018
%U https://link.aps.org/doi/10.1103/PhysRevD.107.055018
%G en
%J Physical Review D
%A Dong, Zhongtian
%A Kong, Kyoungchul
%A Matchev, Konstantin T.
%A Matcheva, Katia
%D 2023-3-13

%0 Journal Article
%T Symbolic machine learning improved MCFT model for punching shear resistance of FRP-reinforced concrete slabs
%V 69
%P 106257
%J Journal of Building Engineering
%A Liang, Shixue
%A Shen, Yuanxie
%A Gao, Xiangling
%A Cai, Yiqing
%A Fei, Zhengyu
%D 2023

%0 Journal Article
%T Axial compressive capacity prediction and optimal design of circular UHPC-filled steel tube based on Hybrid Symbolic Regression - Neural Network model
%V 68
%G en-US
%J STRUCTURES
%A Ren, Zhigang
%A Wang, Dian
%A Kondo, Gen
%D 2024-10

%0 Journal Article
%T Artificial intelligence to deep learning: machine intelligence approach for drug discovery
%V 25
%N 3
%P 1315-1360
%U https://link.springer.com/10.1007/s11030-021-10217-3
%X Drug designing and development is an important area of research for pharmaceutical companies and chemical scientists. However, low efficacy, off-target delivery, time consumption, and high cost impose a hurdle and challenges that impact drug design and discovery. Further, complex and big data from genomics, proteomics, microarray data, and clinical trials also impose an obstacle in the drug discovery pipeline. Artificial intelligence and machine learning technology play a crucial role in drug discovery and development. In other words, artificial neural networks and deep learning algorithms have modernized the area. Machine learning and deep learning algorithms have been implemented in several drug discovery processes such as peptide synthesis, structure-based virtual screening, ligand-based virtual screening, toxicity prediction, drug monitoring and release, pharmacophore modeling, quantitative structure–activity relationship, drug repositioning, polypharmacology, and physiochemical activity. Evidence from the past strengthens the implementation of artificial intelligence and deep learning in this field. Moreover, novel data mining, curation, and management techniques provided critical support to recently developed modeling algorithms. In summary, artificial intelligence and deep learning advancements provide an excellent opportunity for rational drug design and discovery process, which will eventually impact mankind.
%G en
%J Molecular Diversity
%A Gupta, Rohan
%A Srivastava, Devesh
%A Sahu, Mehar
%A Tiwari, Swati
%A Ambasta, Rashmi K.
%A Kumar, Pravir
%D 08/2021

%0 Journal Article
%T Discovery of Physically Interpretable Wave Equations
%U https://link.springer.com/10.1007/s10712-024-09857-5
%X Using symbolic regression to discover physical laws from observed data is an emerging field. In previous work, we combined genetic algorithm (GA) and machine learning to present a data-driven method for discovering a wave equation. Although it managed to utilize the data to discover the two-dimensional (x, z) acoustic constant-density wave equation utt = v2(uxx + uzz) (subscripts of the wavefield, u, are second derivatives in time and space) in a homogeneous medium, it did not provide the complete equation form, where the velocity term is represented by a coefficient rather than directly given by v2. In this work, we redesign the framework, encoding both velocity information and candidate functional terms simultaneously. Thus, we use GA to simultaneously evolve the candidate functional and coefficient terms in the library. Also, we consider here the physics rationality and interpretability in the randomly generated potential wave equations, by ensuring that both-hand sides of the equation maintain balance in their physical units. We demonstrate this redesigned framework using the acoustic wave equation as an example, showing its ability to produce physically reasonable expressions of wave equations from noisy and sparsely observed data in both homogeneous and inhomogeneous media. Also, we demonstrate that our method can effectively discover wave equations from a more realistic observation scenario.
%G en
%J Surveys in Geophysics
%A Cheng, Shijun
%A Alkhalifah, Tariq
%D 2024-09-26

%0 Journal Article
%T Deep Learning and Symbolic Regression for Discovering Parametric Equations
%P 1-13
%* https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html
%U https://ieeexplore.ieee.org/document/10253952/
%X Symbolic regression is a machine learning technique that can learn the equations governing data and thus has the potential to transform scientific discovery. However, symbolic regression is still limited in the complexity and dimensionality of the systems that it can analyze. Deep learning, on the other hand, has transformed machine learning in its ability to analyze extremely complex and high-dimensional datasets. We propose a neural network architecture to extend symbolic regression to parametric systems where some coefficient may vary, but the structure of the underlying governing equation remains constant. We demonstrate our method on various analytic expressions and partial differential equations (PDEs) with varying coefficients and show that it extrapolates well outside of the training domain. The proposed neural-network-based architecture can also be enhanced by integrating with other deep learning architectures such that it can analyze high-dimensional data while being trained end-to-end. To this end, we demonstrate the scalability of our architecture by incorporating a convolutional encoder to analyze 1-D images of varying spring systems.
%G en
%J IEEE Transactions on Neural Networks and Learning Systems
%A Zhang, Michael
%A Kim, Samuel
%A Lu, Peter Y.
%A Soljačić, Marin
%D 2023

%0 Generic
%T Rethinking Symbolic Regression Datasets and Benchmarks for Scientific Discovery
%I arXiv
%U http://arxiv.org/abs/2206.10540
%X This paper revisits datasets and evaluation criteria for Symbolic Regression (SR), specifically focused on its potential for scientific discovery. Focused on a set of formulas used in the existing datasets based on Feynman Lectures on Physics, we recreate 120 datasets to discuss the performance of symbolic regression for scientific discovery (SRSD). For each of the 120 SRSD datasets, we carefully review the properties of the formula and its variables to design reasonably realistic sampling ranges of values so that our new SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an SR method can (re)discover physical laws from such datasets. We also create another 120 datasets that contain dummy variables to examine whether SR methods can choose necessary variables only. Besides, we propose to use normalized edit distances (NED) between a predicted equation and the true equation trees for addressing a critical issue that existing SR metrics are either binary or errors between the target values and an SR model's predicted values for a given input. We conduct benchmark experiments on our new SRSD datasets using various representative SR methods. The experimental results show that we provide a more realistic performance evaluation, and our user study shows that the NED correlates with human judges significantly more than an existing SR metric. We publish repositories of our code and 240 SRSD datasets.
%G en
%A Matsubara, Yoshitomo
%A Chiba, Naoya
%A Igarashi, Ryo
%A Ushiku, Yoshitaka
%D 2024-03-05
%K Computer Science - Artificial Intelligence
Computer Science - Machine Learning
Computer Science - Symbolic Computation
Computer Science - Neural and Evolutionary Computing

%0 Journal Article
%T Simple descriptor derived from symbolic regression accelerating the discovery of new perovskite catalysts
%V 11
%N 1
%P 3513
%U https://www.nature.com/articles/s41467-020-17263-9
%X Abstract
            
              Symbolic regression (SR) is an approach of interpretable machine learning for building mathematical formulas that best fit certain datasets. In this work, SR is used to guide the design of new oxide perovskite catalysts with improved oxygen evolution reaction (OER) activities. A simple descriptor,
              μ
              /
              t
              , where
              μ
              and
              t
              are the octahedral and tolerance factors, respectively, is identified, which accelerates the discovery of a series of new oxide perovskite catalysts with improved OER activity. We successfully synthesise five new oxide perovskites and characterise their OER activities. Remarkably, four of them, Cs
              0.4
              La
              0.6
              Mn
              0.25
              Co
              0.75
              O
              3
              , Cs
              0.3
              La
              0.7
              NiO
              3
              , SrNi
              0.75
              Co
              0.25
              O
              3
              , and Sr
              0.25
              Ba
              0.75
              NiO
              3
              , are among the oxide perovskite catalysts with the highest intrinsic activities. Our results demonstrate the potential of SR for accelerating the data-driven design and discovery of new materials with improved properties.
%G en
%J Nature Communications
%A Weng, Baicheng
%A Song, Zhilong
%A Zhu, Rilong
%A Yan, Qingyu
%A Sun, Qingde
%A Grice, Corey G.
%A Yan, Yanfa
%A Yin, Wan-Jian
%D 2020-07-14

%0 Journal Article
%T Symbolic regression in materials science
%V 9
%N 3
%P 793-805
%U http://link.springer.com/10.1557/mrc.2019.85
%X The authors showcase the potential of symbolic regression as an analytic method for use in materials research. First, the authors brieﬂy describe the current state-of-the-art method, genetic programming-based symbolic regression (GPSR), and recent advances in symbolic regression techniques. Next, the authors discuss industrial applications of symbolic regression and its potential applications in materials science. The authors then present two GPSR use-cases: formulating a transformation kinetics law and showing the learning scheme discovers the well-known Johnson–Mehl–Avrami–Kolmogorov form, and learning the Landau free energy functional form for the displacive tilt transition in perovskite LaNiO3. Finally, the authors propose that symbolic regression techniques should be considered by materials scientists as an alternative to other machine learning-based regression models for learning from data.
%G en
%J MRS Communications
%A Wang, Yiqun
%A Wagner, Nicholas
%A Rondinelli, James M.
%D 09/2019

%0 Journal Article
%T Discovering Mathematical Expressions Through DeepSymNet: A Classification-Based Symbolic Regression Framework
%P 1-15
%* https://creativecommons.org/licenses/by-nc-nd/4.0/
%U https://ieeexplore.ieee.org/document/10327762/
%X Symbolic regression (SR) is the process of finding an unknown mathematical expression given the input and output and has important applications in interpretable machine learning and knowledge discovery. The major difficulty of SR is that finding the expression structure is an NP-hard problem, which makes the entire process time-consuming. In this study, the solution of expression structures was regarded as a classification problem and solved by supervised learning such that SR can be solved quickly by using the solving experience. Techniques for classification tasks, such as equivalent label merging and sample balance, were used to enhance the robustness of the algorithm. We proposed a symbolic network called DeepSymNet to represent symbolic expressions to improve the performance of the algorithm. DeepSymNet has been proven to have a strong representation ability with a shorter label compared to the current popular representation methods, reducing the search space when predicting. Moreover, DeepSymNet conveniently decomposes SR into two smaller subproblems, which makes solving the problem easier. The proposed algorithm was tested on artificially generated expressions and public datasets and compared with other algorithms. The results demonstrate the effectiveness of the proposed algorithm.
%G en
%J IEEE Transactions on Neural Networks and Learning Systems
%A Wu, Min
%A Li, Weijun
%A Yu, Lina
%A Sun, Linjun
%A Liu, Jingyi
%A Li, Wenqiang
%D 2024

%0 Conference Paper
%T DEEP SYMBOLIC REGRESSION: RECOVERING MATHEMATICAL EXPRESSIONS FROM DATA VIA RISK-SEEKING POLICY GRADIENTS
%X Discovering the underlying mathematical expressions describing a dataset is a core challenge for artiﬁcial intelligence. This is the problem of symbolic regression. Despite recent advances in training neural networks to solve complex tasks, deep learning approaches to symbolic regression are underexplored. We propose a framework that leverages deep learning for symbolic regression via a simple idea: use a large model to search the space of small models. Speciﬁcally, we use a recurrent neural network to emit a distribution over tractable mathematical expressions and employ a novel risk-seeking policy gradient to train the network to generate better-ﬁtting expressions. Our algorithm outperforms several baseline methods (including Eureqa, the gold standard for symbolic regression) in its ability to exactly recover symbolic expressions on a series of benchmark problems, both with and without added noise. More broadly, our contributions include a framework that can be applied to optimize hierarchical, variable-length objects under a blackbox performance metric, with the ability to incorporate constraints in situ, and a risk-seeking policy gradient formulation that optimizes for best-case performance instead of expected performance.
%G en
%B ICLR 2021
%A Petersen, Brenden K
%A Larma, Mikel Landajuela
%A Mundhenk, T Nathan
%A Santiago, Claudio P
%A Kim, Soo K
%A Kim, Joanne T
%D 2021
%K Computer Science - Machine Learning
Statistics - Machine Learning

%0 Conference Paper
%T Deep Generative Symbolic Regression
%I arXiv
%U http://arxiv.org/abs/2401.00282
%X Symbolic regression (SR) aims to discover concise closed-form mathematical equations from data, a task fundamental to scientific discovery. However, the problem is highly challenging because closed-form equations lie in a complex combinatorial search space. Existing methods, ranging from heuristic search to reinforcement learning, fail to scale with the number of input variables. We make the observation that closed-form equations often have structural characteristics and invariances (e.g., the commutative law) that could be further exploited to build more effective symbolic regression solutions. Motivated by this observation, our key contribution is to leverage pre-trained deep generative models to capture the intrinsic regularities of equations, thereby providing a solid foundation for subsequent optimization steps. We show that our novel formalism unifies several prominent approaches of symbolic regression and offers a new perspective to justify and improve on the previous ad hoc designs, such as the usage of cross-entropy loss during pre-training. Specifically, we propose an instantiation of our framework, Deep Generative Symbolic Regression (DGSR). In our experiments, we show that DGSR achieves a higher recovery rate of true equations in the setting of a larger number of input variables, and it is more computationally efficient at inference time than state-of-the-art RL symbolic regression solutions.
%G en
%B ICLR 2023
%A Holt, Samuel
%A Qian, Zhaozhi
%A Schaar, Mihaela van der
%D 2023-12-30
%K Computer Science - Machine Learning

%0 Journal Article
%T Interpretable machine learning for science with PySR and SymbolicRegression. jl
%J arXiv preprint arXiv:2305.01582
%A Cranmer, Miles
%D 2023

%0 Journal Article
%T Physics-informed learning of governing equations from scarce data
%V 12
%N 1
%P 6136
%U https://www.nature.com/articles/s41467-021-26434-1
%X Abstract
            Harnessing data to discover the underlying governing laws or equations that describe the behavior of complex physical systems can significantly advance our modeling, simulation and understanding of such systems in various science and engineering disciplines. This work introduces a novel approach called physics-informed neural network with sparse regression to discover governing partial differential equations from scarce and noisy data for nonlinear spatiotemporal systems. In particular, this discovery approach seamlessly integrates the strengths of deep neural networks for rich representation learning, physics embedding, automatic differentiation and sparse regression to approximate the solution of system variables, compute essential derivatives, as well as identify the key derivative terms and parameters that form the structure and explicit expression of the equations. The efficacy and robustness of this method are demonstrated, both numerically and experimentally, on discovering a variety of partial differential equation systems with different levels of data scarcity and noise accounting for different initial/boundary conditions. The resulting computational framework shows the potential for closed-form model discovery in practical applications where large and accurate datasets are intractable to capture.
%G en
%J Nature Communications
%A Chen, Zhao
%A Liu, Yang
%A Sun, Hao
%D 2021-10-21

%0 Generic
%T Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks
%I arXiv
%U http://arxiv.org/abs/1810.00825
%X Many machine learning tasks such as multiple instance learning, 3D shape recognition and fewshot image classiﬁcation are deﬁned on sets of instances. Since solutions to such problems do not depend on the order of elements of the set, models used to address them should be permutation invariant. We present an attention-based neural network module, the Set Transformer, speciﬁcally designed to model interactions among elements in the input set. The model consists of an encoder and a decoder, both of which rely on attention mechanisms. In an effort to reduce computational complexity, we introduce an attention scheme inspired by inducing point methods from sparse Gaussian process literature. It reduces computation time of self-attention from quadratic to linear in the number of elements in the set. We show that our model is theoretically attractive and we evaluate it on a range of tasks, demonstrating increased performance compared to recent methods for set-structured data.
%G en
%A Lee, Juho
%A Lee, Yoonho
%A Kim, Jungtaek
%A Kosiorek, Adam R.
%A Choi, Seungjin
%A Teh, Yee Whye
%D 2019-05-26
%K Computer Science - Machine Learning
Statistics - Machine Learning

%0 Generic
%T Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
%I arXiv
%U http://arxiv.org/abs/1910.10683
%X Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new ``Colossal Clean Crawled Corpus'', we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.
%G en
%A Raffel, Colin
%A Shazeer, Noam
%A Roberts, Adam
%A Lee, Katherine
%A Narang, Sharan
%A Matena, Michael
%A Zhou, Yanqi
%A Li, Wei
%A Liu, Peter J.
%D 2023-09-19
%K Computer Science - Computation and Language
Computer Science - Machine Learning
Statistics - Machine Learning

%0 Generic
%T Neural Symbolic Regression that Scales
%I arXiv
%U http://arxiv.org/abs/2106.06427
%X Symbolic equations are at the core of scientiﬁc discovery. The task of discovering the underlying equation from a set of input-output pairs is called symbolic regression. Traditionally, symbolic regression methods use hand-designed strategies that do not improve with experience. In this paper, we introduce the ﬁrst symbolic regression method that leverages large scale pre-training. We procedurally generate an unbounded set of equations, and simultaneously pre-train a Transformer to predict the symbolic equation from a corresponding set of input-output-pairs. At test time, we query the model on a new set of points and use its output to guide the search for the equation. We show empirically that this approach can re-discover a set of well-known physical equations, and that it improves over time with more data and compute.
%G en
%A Biggio, Luca
%A Bendinelli, Tommaso
%A Neitz, Alexander
%A Lucchi, Aurelien
%A Parascandolo, Giambattista
%D 2021-06-11
%K Computer Science - Machine Learning

%0 Generic
%T SymbolicGPT: A Generative Transformer Model for Symbolic Regression
%I arXiv
%U http://arxiv.org/abs/2106.14131
%X Symbolic regression is the task of identifying a mathematical expression that best ﬁts a provided dataset of input and output values. Due to the richness of the space of mathematical expressions, symbolic regression is generally a challenging problem. While conventional approaches based on genetic evolution algorithms have been used for decades, deep learning-based methods are relatively new and an active research area. In this work, we present SymbolicGPT, a novel transformer-based language model for symbolic regression3. This model exploits the advantages of probabilistic language models like GPT, including strength in performance and ﬂexibility. Through comprehensive experiments, we show that our model performs strongly compared to competing models with respect to the accuracy, running time, and data efﬁciency.
%G en
%A Valipour, Mojtaba
%A You, Bowen
%A Panju, Maysum
%A Ghodsi, Ali
%D 2021-06-27
%K Computer Science - Computation and Language
Computer Science - Machine Learning
Computer Science - Symbolic Computation

%0 Journal Article
%T Deep Symbolic Regression for Physics Guided by Units Constraints: Toward the Automated Discovery of Physical Laws
%V 959
%N 2
%P 99
%U https://iopscience.iop.org/article/10.3847/1538-4357/ad014c
%X Symbolic regression (SR) is the study of algorithms that automate the search for analytic expressions that ﬁt data. While recent advances in deep learning have generated renewed interest in such approaches, the development of SR methods has not been focused on physics, where we have important additional constraints due to the units associated with our data. Here we present Φ-SO, a physical symbolic optimization framework for recovering analytical symbolic expressions from physics data using deep reinforcement learning techniques by learning units constraints. Our system is built, from the ground up, to propose solutions where the physical units are consistent by construction. This is useful not only in eliminating physically impossible solutions but also because the grammatical rules of dimensional analysis enormously restrict the freedom of the equation generator, thus vastly improving performance. The algorithm can be used to ﬁt noiseless data, which can be useful, for instance, when attempting to derive an analytical property of a physical model, and it can also be used to obtain analytical approximations of noisy data. We test our machinery on a standard benchmark of equations from the Feynman Lectures on Physics and other physics textbooks, achieving state-of-the-art performance in the presence of noise (exceeding 0.1%) and show that it is robust even in the presence of substantial (10%) noise. We showcase its abilities on a panel of examples from astrophysics.
%G en
%J The Astrophysical Journal
%A Tenachi, Wassim
%A Ibata, Rodrigo
%A Diakogiannis, Foivos I.
%D 2023-12-01

%0 Journal Article
%T SRBench++: Principled Benchmarking of Symbolic Regression With Domain-Expert Interpretation
%P 1-1
%* https://creativecommons.org/licenses/by/4.0/legalcode
%U https://ieeexplore.ieee.org/document/10586218/
%X Symbolic regression searches for analytic expressions that accurately describe studied phenomena. The main promise of this approach is that it may return an interpretable model that can be insightful to users, while maintaining high accuracy. The current standard for benchmarking these algorithms is SRBench, which evaluates methods on hundreds of datasets that are a mix of real-world and simulated processes spanning multiple domains. At present, the ability of SRBench to evaluate interpretability is limited to measuring the size of expressions on real-world data, and the exactness of model forms on synthetic data. In practice, model size is only one of many factors used by subject experts to determine how interpretable a model truly is. Furthermore, SRBench does not characterize algorithm performance on speciﬁc, challenging sub-tasks of regression such as feature selection and evasion of local minima. In this work, we propose and evaluate an approach to benchmarking SR algorithms that addresses these limitations of SRBench by 1) incorporating expert evaluations of interpretability on a domain-speciﬁc task, and 2) evaluating algorithms over distinct properties of data science tasks. We evaluate 12 modern symbolic regression algorithms on these benchmarks and present an in-depth analysis of the results, discuss current challenges of symbolic regression algorithms and highlight possible improvements for the benchmark itself.
%G en
%J IEEE Transactions on Evolutionary Computation
%A De Franca, F. O.
%A Virgolin, M.
%A Kommenda, M.
%A Majumder, M. S.
%A Cranmer, M.
%A Espada, G.
%A Ingelse, L.
%A Fonseca, A.
%A Landajuela, M.
%A Petersen, B.
%A Glatt, R.
%A Mundhenk, N.
%A Lee, C. S.
%A Hochhalter, J. D.
%A Randall, D. L.
%A Kamienny, P.
%A Zhang, H.
%A Dick, G.
%A Simon, A.
%A Burlacu, B.
%A Kasak, Jaan
%A Machado, Meera
%A Wilstrup, Casper
%A Cavaz, W. G. La
%D 2024

%0 Conference Paper
%T A Unified Framework for Deep Symbolic Regression
%X The last few years have witnessed a surge in methods for symbolic regression, from advances in traditional evolutionary approaches to novel deep learning-based systems. Individual works typically focus on advancing the state-of-the-art for one particular class of solution strategies, and there have been few attempts to investigate the beneﬁts of hybridizing or integrating multiple strategies. In this work, we identify ﬁve classes of symbolic regression solution strategies—recursive problem simpliﬁcation, neural-guided search, large-scale pre-training, genetic programming, and linear models—and propose a strategy to hybridize them into a single modular, uniﬁed symbolic regression framework. Based on empirical evaluation using SRBench, a new community tool for benchmarking symbolic regression methods, our uniﬁed framework achieves state-of-the-art performance in its ability to (1) symbolically recover analytical expressions, (2) ﬁt datasets with high accuracy, and (3) balance accuracy-complexity trade-offs, across 252 ground-truth and black-box benchmark problems, in both noiseless settings and across various noise levels. Finally, we provide practical use case-based guidance for constructing hybrid symbolic regression algorithms, supported by extensive, combinatorial ablation studies.
%G en
%B NeurIPS 2022
%A Landajuela, Mikel
%A Lee, Chak Shing
%A Yang, Jiachen
%A Glatt, Ruben
%A Santiago, Claudio
%A Mundhenk, T Nathan
%A Aravena, Ignacio
%A Mulcahy, Garrett
%A Petersen, Brenden
%D 2022

%0 Journal Article
%T Artificial Intelligence in Physical Sciences: Symbolic Regression Trends and Perspectives
%V 30
%N 6
%P 3845-3865
%U https://link.springer.com/10.1007/s11831-023-09922-z
%X Symbolic regression (SR) is a machine learning-based regression method based on genetic programming principles that integrates techniques and processes from heterogeneous scientific fields and is capable of providing analytical equations purely from data. This remarkable characteristic diminishes the need to incorporate prior knowledge about the investigated system. SR can spot profound and elucidate ambiguous relations that can be generalizable, applicable, explainable and span over most scientific, technological, economical, and social principles. In this review, current state of the art is documented, technical and physical characteristics of SR are presented, the available programming techniques are investigated, fields of application are explored, and future perspectives are discussed.
%G en
%J Archives of Computational Methods in Engineering
%A Angelis, Dimitrios
%A Sofos, Filippos
%A Karakasidis, Theodoros E.
%D 07/2023

%0 Journal Article
%T AI Feynman: A physics-inspired method for symbolic regression
%V 6
%N 16
%P eaay2631
%U https://www.science.org/doi/10.1126/sciadv.aay2631
%X 【AIFeynman，曾经的GOAT】
Our physics-inspired algorithm for symbolic regression is able to discover complex physics equations from mere tables of numbers.
              A core challenge for both physics and artificial intelligence (AI) is symbolic regression: finding a symbolic expression that matches data from an unknown function. Although this problem is likely to be NP-hard in principle, functions of practical interest often exhibit symmetries, separability, compositionality, and other simplifying properties. In this spirit, we develop a recursive multidimensional symbolic regression algorithm that combines neural network fitting with a suite of physics-inspired techniques. We apply it to 100 equations from the
              Feynman Lectures on Physics
              , and it discovers all of them, while previous publicly available software cracks only 71; for a more difficult physics-based test set, we improve the state-of-the-art success rate from 15 to 90%.
%G en
%J Science Advances
%A Udrescu, Silviu-Marian
%A Tegmark, Max
%D 2020-04-17

%0 Journal Article
%T SymFormer: End-to-End Symbolic Regression Using Transformer-Based Architecture
%V 12
%P 37840-37849
%* https://creativecommons.org/licenses/by/4.0/legalcode
%U https://ieeexplore.ieee.org/document/10462113/
%X Many real-world systems can be naturally described by mathematical formulas. The task of automatically constructing formulas to fit observed data is called symbolic regression. Evolutionary methods such as genetic programming have been commonly used to solve symbolic regression tasks, but they have significant drawbacks, such as high computational complexity. Recently, neural networks have been applied to symbolic regression, among which the transformer-based methods seem to be most promising. After training a transformer on a large number of formulas, the actual inference, i.e., finding a formula for new, unseen data, is very fast (in the order of seconds). This is considerably faster than state-ofthe-art evolutionary methods. The main drawback of transformers is that they generate formulas without numerical constants, which have to be optimized separately, yielding suboptimal results. We propose a transformer-based approach called SymFormer, which predicts the formula by outputting the symbols and the constants simultaneously. This helps to generate formulas that fit the data more accurately. In addition, the constants provided by SymFormer serve as a good starting point for subsequent tuning via gradient descent to further improve the model accuracy. We show on several benchmarks that SymFormer outperforms stateof-the-art methods while having faster inference.
%G en
%J IEEE Access
%A Vastl, Martin
%A Kulhánek, Jonáš
%A Kubalík, Jiří
%A Derner, Erik
%A Babuška, Robert
%D 2024

%0 Journal Article
%T Interpretable scientific discovery with symbolic regression: a review
%V 57
%N 1
%P 2
%U https://link.springer.com/10.1007/s10462-023-10622-0
%X Symbolic regression is emerging as a promising machine learning method for learning succinct underlying interpretable mathematical expressions directly from data. Whereas it has been traditionally tackled with genetic programming, it has recently gained a growing interest in deep learning as a data-driven model discovery tool, achieving significant advances in various application domains ranging from fundamental to applied sciences. In this survey, we present a structured and comprehensive overview of symbolic regression methods, review the adoption of these methods for model discovery in various areas, and assess their effectiveness. We have also grouped state-of-the-art symbolic regression applications in a categorized manner in a living review.
%G en
%J Artificial Intelligence Review
%A Makke, Nour
%A Chawla, Sanjay
%D 01/2024

%0 Journal Article
%T Toward Physically Plausible Data-Driven Models: A Novel Neural Network Approach to Symbolic Regression
%V 11
%P 61481-61501
%* https://creativecommons.org/licenses/by/4.0/legalcode
%U https://ieeexplore.ieee.org/document/10155126/
%X Many real-world systems can be described by mathematical models that are humancomprehensible, easy to analyze and help explain the system’s behavior. Symbolic regression is a method that can automatically generate such models from data. Historically, symbolic regression has been predominantly realized by genetic programming, a method that evolves populations of candidate solutions that are subsequently modified by genetic operators crossover and mutation. However, this approach suffers from several deficiencies: it does not scale well with the number of variables and samples in the training data –models tend to grow in size and complexity without an adequate accuracy gain, and it is hard to fine-tune the model coefficients using just genetic operators. Recently, neural networks have been applied to learn the whole analytic model, i.e., its structure and the coefficients, using gradient-based optimization algorithms. This paper proposes a novel neural network-based symbolic regression method that constructs physically plausible models based on even very small training data sets and prior knowledge about the system. The method employs an adaptive weighting scheme to effectively deal with multiple loss function terms and an epoch-wise learning process to reduce the chance of getting stuck in poor local optima. Furthermore, we propose a parameter-free method for choosing the model with the best interpolation and extrapolation performance out of all the models generated throughout the whole learning process. We experimentally evaluate the approach on four test systems: the TurtleBot 2 mobile robot, the magnetic manipulation system, the equivalent resistance of two resistors in parallel, and the longitudinal force of the anti-lock braking system. The results clearly show the potential of the method to find parsimonious models that comply with the prior knowledge provided.
%G en
%J IEEE Access
%A Kubalík, Jiří
%A Derner, Erik
%A Babuška, Robert
%D 2023

%0 Journal Article
%T A computational framework for physics-informed symbolic regression with straightforward integration of domain knowledge
%V 13
%N 1
%P 1249
%U https://www.nature.com/articles/s41598-023-28328-2
%X Discovering a meaningful symbolic expression that explains experimental data is a fundamental challenge in many scientific fields. We present a novel, open-source computational framework called
              Scientist-Machine Equation Detector
              (SciMED), which integrates scientific discipline wisdom in a scientist-in-the-loop approach, with state-of-the-art symbolic regression (SR) methods. SciMED combines a wrapper selection method, that is based on a genetic algorithm, with automatic machine learning and two levels of SR methods. We test SciMED on five configurations of a settling sphere, with and without aerodynamic non-linear drag force, and with excessive noise in the measurements. We show that SciMED is sufficiently robust to discover the correct physically meaningful symbolic expressions from the data, and demonstrate how the integration of domain knowledge enhances its performance. Our results indicate better performance on these tasks than the state-of-the-art SR software packages , even in cases where no knowledge is integrated. Moreover, we demonstrate how SciMED can alert the user about possible missing features, unlike the majority of current SR systems.
%G en
%J Scientific Reports
%A Keren, Liron Simon
%A Liberzon, Alex
%A Lazebnik, Teddy
%D 2023-01-23

%0 Conference Paper
%T Contemporary Symbolic Regression Methods and their Relative Performance
%I arXiv
%U http://arxiv.org/abs/2107.14351
%X Many promising approaches to symbolic regression have been presented in recent years, yet progress in the ﬁeld continues to suffer from a lack of uniform, robust, and transparent benchmarking standards. In this paper, we address this shortcoming by introducing an open-source, reproducible benchmarking platform for symbolic regression. We assess 14 symbolic regression methods and 7 machine learning methods on a set of 252 diverse regression problems. Our assessment includes both real-world datasets with no known model form as well as ground-truth benchmark problems, including physics equations and systems of ordinary differential equations. For the real-world datasets, we benchmark the ability of each method to learn models with low error and low complexity relative to state-of-the-art machine learning methods. For the synthetic problems, we assess each method’s ability to ﬁnd exact solutions in the presence of varying levels of noise. Under these controlled experiments, we conclude that the best performing methods for real-world regression combine genetic algorithms with parameter estimation and/or semantic search drivers. When tasked with recovering exact equations in the presence of noise, we ﬁnd that deep learning and genetic algorithm-based approaches perform similarly. We provide a detailed guide to reproducing this experiment and contributing new methods, and encourage other researchers to collaborate with us on a common and living symbolic regression benchmark.
%G en
%B NeurIPS 2021
%A La Cava, William
%A Orzechowski, Patryk
%A Burlacu, Bogdan
%A de França, Fabrício Olivetti
%A Virgolin, Marco
%A Jin, Ying
%A Kommenda, Michael
%A Moore, Jason H.
%D 2021-07-29

%0 Journal Article
%T Rediscovering orbital mechanics with machine learning
%U http://arxiv.org/abs/2202.02306
%X We present an approach for using machine learning to automatically discover the governing equations and hidden properties of real physical systems from observations. We train a “graph neural network” to simulate the dynamics of our solar system’s Sun, planets, and large moons from 30 years of trajectory data. We then use symbolic regression to discover an analytical expression for the force law implicitly learned by the neural network, which our results showed is equivalent to Newton’s law of gravitation. The key assumptions that were required were translational and rotational equivariance, and Newton’s second and third laws of motion. Our approach correctly discovered the form of the symbolic force law. Furthermore, our approach did not require any assumptions about the masses of planets and moons or physical constants. They, too, were accurately inferred through our methods. Though, of course, the classical law of gravitation has been known since Isaac Newton, our result serves as a validation that our method can discover unknown laws and hidden properties from observed data. More broadly this work represents a key step toward realizing the potential of machine learning for accelerating scientiﬁc discovery.
%G en
%J Machine Learning: Science and Technology
%A Lemos, Pablo
%A Jeffrey, Niall
%A Cranmer, Miles
%A Ho, Shirley
%A Battaglia, Peter
%D 2022-02-04
%K Astrophysics - Earth and Planetary Astrophysics

%0 Conference Paper
%T Transformer-based Planning for Symbolic Regression
%X Symbolic regression (SR) is a challenging task in machine learning that involves finding a mathematical expression for a function based on its values. Recent advancements in SR have demonstrated the effectiveness of pre-trained transformer models in generating equations as sequences, leveraging large-scale pre-training on synthetic datasets and offering notable advantages in terms of inference time over classical Genetic Programming (GP) methods. However, these models primarily rely on supervised pre-training objectives borrowed from text generation and overlook equation discovery goals like accuracy and complexity. To address this, we propose TPSR, a Transformer-based Planning strategy for Symbolic Regression that incorporates Monte Carlo Tree Search planning algorithm into the transformer decoding process. Unlike conventional decoding strategies, TPSR enables the integration of non-differentiable equation verification feedback, such as fitting accuracy and complexity, as external sources of knowledge into the transformer equation generation process. Extensive experiments on various datasets show that our approach outperforms state-of-the-art methods, enhancing the model’s fitting-complexity trade-off, extrapolation abilities, and robustness to noise 1 .
%G en
%B NeurIPS 2023
%A Shojaee, Parshin
%A Meidani, Kazem
%A Farimani, Amir Barati
%A Reddy, Chandan K
%D 2023

%0 Conference Paper
%T End-to-end Symbolic Regression with Transformers
%X Symbolic regression, the task of predicting the mathematical expression of a function from the observation of its values, is a difﬁcult task which usually involves a two-step procedure: predicting the "skeleton" of the expression up to the choice of numerical constants, then ﬁtting the constants by optimizing a non-convex loss function. The dominant approach is genetic programming, which evolves candidates by iterating this subroutine a large number of times. Neural networks have recently been tasked to predict the correct skeleton in a single try, but remain much less powerful.
%G en
%B NeurIPS 2022
%A Kamienny, Pierre-Alexandre
%A Lample, Guillaume
%A Charton, François
%D 2022

%0 Conference Paper
%T Deep Symbolic Regression for Recurrent Sequences
%I arXiv
%U http://arxiv.org/abs/2201.04600
%X Symbolic regression, i.e. predicting a function from the observation of its values, is well-known to be a challenging task. In this paper, we train Transformers to infer the function or recurrence relation underlying sequences of integers or floats, a typical task in human IQ tests which has hardly been tackled in the machine learning literature. We evaluate our integer model on a subset of OEIS sequences, and show that it outperforms built-in Mathematica functions for recurrence prediction. We also demonstrate that our float model is able to yield informative approximations of out-of-vocabulary functions and constants, e.g. $\operatorname{bessel0}(x)\approx \frac{\sin(x)+\cos(x)}{\sqrt{\pi x}}$ and $1.644934\approx \pi^2/6$. An interactive demonstration of our models is provided at https://symbolicregression.metademolab.com.
%G en
%B ICML 2022
%A d'Ascoli, Stéphane
%A Kamienny, Pierre-Alexandre
%A Lample, Guillaume
%A Charton, François
%D 2022-06-28
%K Computer Science - Machine Learning

%0 Journal Article
%T Class Symbolic Regression: Gotta Fit ’Em All
%V 969
%N 2
%P L26
%U https://iopscience.iop.org/article/10.3847/2041-8213/ad5970
%X We introduce “Class Symbolic Regression” (Class SR), the first framework for automatically finding a single analytical functional form that accurately fits multiple data sets—each realization being governed by its own (possibly) unique set of fitting parameters. This hierarchical framework leverages the common constraint that all the members of a single class of physical phenomena follow a common governing law. Our approach extends the capabilities of our earlier Physical Symbolic Optimization (Φ-SO) framework for symbolic regression, which integrates dimensional analysis constraints and deep reinforcement learning for unsupervised symbolic analytical function discovery from data. Additionally, we introduce the first Class SR benchmark, comprising a series of synthetic physical challenges specifically designed to evaluate such algorithms. We demonstrate the efficacy of our novel approach by applying it to these benchmark challenges and showcase its practical utility for astrophysics by successfully extracting an analytic galaxy potential from a set of simulated orbits approximating stellar streams.
%G en
%J The Astrophysical Journal Letters
%A Tenachi, Wassim
%A Ibata, Rodrigo
%A François, Thibaut L.
%A Diakogiannis, Foivos I.
%D 2024-07-01

%0 Conference Paper
%T Deep Learning for Symbolic Mathematics
%I arXiv
%U http://arxiv.org/abs/1912.01412
%X Neural networks have a reputation for being better at solving statistical or approximate problems than at performing calculations or working with symbolic data. In this paper, we show that they can be surprisingly good at more elaborated tasks in mathematics, such as symbolic integration and solving differential equations. We propose a syntax for representing mathematical problems, and methods for generating large datasets that can be used to train sequence-to-sequence models. We achieve results that outperform commercial Computer Algebra Systems such as Matlab or Mathematica.
%G en
%B ICLR 2020
%A Lample, Guillaume
%A Charton, François
%D 2019-12-02
%K Computer Science - Machine Learning
Computer Science - Symbolic Computation

%0 Journal Article
%T SymPy: symbolic computing in Python
%V 3
%P e103
%* http://creativecommons.org/licenses/by/4.0/
%U https://peerj.com/articles/cs-103
%X SymPy is an open source computer algebra system written in pure Python. It is built with a focus on extensibility and ease of use, through both interactive and programmatic applications. These characteristics have led SymPy to become a popular symbolic library for the scientific Python ecosystem. This paper presents the architecture of SymPy, a description of its features, and a discussion of select submodules. The supplementary material provide additional examples and further outline details of the architecture and features of SymPy.
%G en
%J PeerJ Computer Science
%A Meurer, Aaron
%A Smith, Christopher P.
%A Paprocki, Mateusz
%A Čertík, Ondřej
%A Kirpichev, Sergey B.
%A Rocklin, Matthew
%A Kumar, AMiT
%A Ivanov, Sergiu
%A Moore, Jason K.
%A Singh, Sartaj
%A Rathnayake, Thilina
%A Vig, Sean
%A Granger, Brian E.
%A Muller, Richard P.
%A Bonazzi, Francesco
%A Gupta, Harsh
%A Vats, Shivam
%A Johansson, Fredrik
%A Pedregosa, Fabian
%A Curry, Matthew J.
%A Terrel, Andy R.
%A Roučka, Štěpán
%A Saboo, Ashutosh
%A Fernando, Isuru
%A Kulal, Sumith
%A Cimrman, Robert
%A Scopatz, Anthony
%D 2017-01-02

%0 Conference Paper
%T A Seq2Seq approach to Symbolic Regression
%X Deep neural networks have proved to be powerful function approximators. The large hypothesis space they implicitly model allows them to ﬁt very complicated black-box functions to the training data. However, often the data generating process is characterized by a concise and relatively simple functional form. This is especially true in natural sciences, where elegant physical laws govern the behaviour of the quantities of interest. In this work, we address this dichotomy from the perspective of Symbolic Regression (SR). In particular, we apply a fully-convolutional seq2seq model to map numerical data to the corresponding symbolic equations. We demonstrate the effectiveness of our approach on a large set of mathematical expressions by providing both a qualitative and a quantitative analysis of our results. Additionally, we release our new equation-generator Python library in order to facilitate benchmarking and stimulate new research on SR1.
%G en
%B NeurIPS 2020
%A Biggio, Luca
%A Bendinelli, Tommaso
%A Lucchi, Aurelien
%A Parascandolo, Giambattista
%D 2020

%0 Journal Article
%T Is the machine smarter than the theorist: Deriving formulas for particle kinematics with symbolic regression
%V 107
%N 5
%P 055018
%U https://link.aps.org/doi/10.1103/PhysRevD.107.055018
%G en
%J Physical Review D
%A Dong, Zhongtian
%A Kong, Kyoungchul
%A Matchev, Konstantin T.
%A Matcheva, Katia
%D 2023-3-13

%0 Journal Article
%T Symbolic machine learning improved MCFT model for punching shear resistance of FRP-reinforced concrete slabs
%V 69
%P 106257
%J Journal of Building Engineering
%A Liang, Shixue
%A Shen, Yuanxie
%A Gao, Xiangling
%A Cai, Yiqing
%A Fei, Zhengyu
%D 2023

%0 Journal Article
%T Axial compressive capacity prediction and optimal design of circular UHPC-filled steel tube based on Hybrid Symbolic Regression - Neural Network model
%V 68
%G en-US
%J STRUCTURES
%A Ren, Zhigang
%A Wang, Dian
%A Kondo, Gen
%D 2024-10

%0 Journal Article
%T Artificial intelligence to deep learning: machine intelligence approach for drug discovery
%V 25
%N 3
%P 1315-1360
%U https://link.springer.com/10.1007/s11030-021-10217-3
%X Drug designing and development is an important area of research for pharmaceutical companies and chemical scientists. However, low efficacy, off-target delivery, time consumption, and high cost impose a hurdle and challenges that impact drug design and discovery. Further, complex and big data from genomics, proteomics, microarray data, and clinical trials also impose an obstacle in the drug discovery pipeline. Artificial intelligence and machine learning technology play a crucial role in drug discovery and development. In other words, artificial neural networks and deep learning algorithms have modernized the area. Machine learning and deep learning algorithms have been implemented in several drug discovery processes such as peptide synthesis, structure-based virtual screening, ligand-based virtual screening, toxicity prediction, drug monitoring and release, pharmacophore modeling, quantitative structure–activity relationship, drug repositioning, polypharmacology, and physiochemical activity. Evidence from the past strengthens the implementation of artificial intelligence and deep learning in this field. Moreover, novel data mining, curation, and management techniques provided critical support to recently developed modeling algorithms. In summary, artificial intelligence and deep learning advancements provide an excellent opportunity for rational drug design and discovery process, which will eventually impact mankind.
%G en
%J Molecular Diversity
%A Gupta, Rohan
%A Srivastava, Devesh
%A Sahu, Mehar
%A Tiwari, Swati
%A Ambasta, Rashmi K.
%A Kumar, Pravir
%D 08/2021

%0 Journal Article
%T Discovery of Physically Interpretable Wave Equations
%U https://link.springer.com/10.1007/s10712-024-09857-5
%X Using symbolic regression to discover physical laws from observed data is an emerging field. In previous work, we combined genetic algorithm (GA) and machine learning to present a data-driven method for discovering a wave equation. Although it managed to utilize the data to discover the two-dimensional (x, z) acoustic constant-density wave equation utt = v2(uxx + uzz) (subscripts of the wavefield, u, are second derivatives in time and space) in a homogeneous medium, it did not provide the complete equation form, where the velocity term is represented by a coefficient rather than directly given by v2. In this work, we redesign the framework, encoding both velocity information and candidate functional terms simultaneously. Thus, we use GA to simultaneously evolve the candidate functional and coefficient terms in the library. Also, we consider here the physics rationality and interpretability in the randomly generated potential wave equations, by ensuring that both-hand sides of the equation maintain balance in their physical units. We demonstrate this redesigned framework using the acoustic wave equation as an example, showing its ability to produce physically reasonable expressions of wave equations from noisy and sparsely observed data in both homogeneous and inhomogeneous media. Also, we demonstrate that our method can effectively discover wave equations from a more realistic observation scenario.
%G en
%J Surveys in Geophysics
%A Cheng, Shijun
%A Alkhalifah, Tariq
%D 2024-09-26

%0 Journal Article
%T Deep Learning and Symbolic Regression for Discovering Parametric Equations
%P 1-13
%* https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html
%U https://ieeexplore.ieee.org/document/10253952/
%X Symbolic regression is a machine learning technique that can learn the equations governing data and thus has the potential to transform scientific discovery. However, symbolic regression is still limited in the complexity and dimensionality of the systems that it can analyze. Deep learning, on the other hand, has transformed machine learning in its ability to analyze extremely complex and high-dimensional datasets. We propose a neural network architecture to extend symbolic regression to parametric systems where some coefficient may vary, but the structure of the underlying governing equation remains constant. We demonstrate our method on various analytic expressions and partial differential equations (PDEs) with varying coefficients and show that it extrapolates well outside of the training domain. The proposed neural-network-based architecture can also be enhanced by integrating with other deep learning architectures such that it can analyze high-dimensional data while being trained end-to-end. To this end, we demonstrate the scalability of our architecture by incorporating a convolutional encoder to analyze 1-D images of varying spring systems.
%G en
%J IEEE Transactions on Neural Networks and Learning Systems
%A Zhang, Michael
%A Kim, Samuel
%A Lu, Peter Y.
%A Soljačić, Marin
%D 2023

%0 Generic
%T Rethinking Symbolic Regression Datasets and Benchmarks for Scientific Discovery
%I arXiv
%U http://arxiv.org/abs/2206.10540
%X This paper revisits datasets and evaluation criteria for Symbolic Regression (SR), specifically focused on its potential for scientific discovery. Focused on a set of formulas used in the existing datasets based on Feynman Lectures on Physics, we recreate 120 datasets to discuss the performance of symbolic regression for scientific discovery (SRSD). For each of the 120 SRSD datasets, we carefully review the properties of the formula and its variables to design reasonably realistic sampling ranges of values so that our new SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an SR method can (re)discover physical laws from such datasets. We also create another 120 datasets that contain dummy variables to examine whether SR methods can choose necessary variables only. Besides, we propose to use normalized edit distances (NED) between a predicted equation and the true equation trees for addressing a critical issue that existing SR metrics are either binary or errors between the target values and an SR model's predicted values for a given input. We conduct benchmark experiments on our new SRSD datasets using various representative SR methods. The experimental results show that we provide a more realistic performance evaluation, and our user study shows that the NED correlates with human judges significantly more than an existing SR metric. We publish repositories of our code and 240 SRSD datasets.
%G en
%A Matsubara, Yoshitomo
%A Chiba, Naoya
%A Igarashi, Ryo
%A Ushiku, Yoshitaka
%D 2024-03-05
%K Computer Science - Artificial Intelligence
Computer Science - Machine Learning
Computer Science - Symbolic Computation
Computer Science - Neural and Evolutionary Computing

%0 Journal Article
%T Simple descriptor derived from symbolic regression accelerating the discovery of new perovskite catalysts
%V 11
%N 1
%P 3513
%U https://www.nature.com/articles/s41467-020-17263-9
%X Abstract
            
              Symbolic regression (SR) is an approach of interpretable machine learning for building mathematical formulas that best fit certain datasets. In this work, SR is used to guide the design of new oxide perovskite catalysts with improved oxygen evolution reaction (OER) activities. A simple descriptor,
              μ
              /
              t
              , where
              μ
              and
              t
              are the octahedral and tolerance factors, respectively, is identified, which accelerates the discovery of a series of new oxide perovskite catalysts with improved OER activity. We successfully synthesise five new oxide perovskites and characterise their OER activities. Remarkably, four of them, Cs
              0.4
              La
              0.6
              Mn
              0.25
              Co
              0.75
              O
              3
              , Cs
              0.3
              La
              0.7
              NiO
              3
              , SrNi
              0.75
              Co
              0.25
              O
              3
              , and Sr
              0.25
              Ba
              0.75
              NiO
              3
              , are among the oxide perovskite catalysts with the highest intrinsic activities. Our results demonstrate the potential of SR for accelerating the data-driven design and discovery of new materials with improved properties.
%G en
%J Nature Communications
%A Weng, Baicheng
%A Song, Zhilong
%A Zhu, Rilong
%A Yan, Qingyu
%A Sun, Qingde
%A Grice, Corey G.
%A Yan, Yanfa
%A Yin, Wan-Jian
%D 2020-07-14

%0 Journal Article
%T Symbolic regression in materials science
%V 9
%N 3
%P 793-805
%U http://link.springer.com/10.1557/mrc.2019.85
%X The authors showcase the potential of symbolic regression as an analytic method for use in materials research. First, the authors brieﬂy describe the current state-of-the-art method, genetic programming-based symbolic regression (GPSR), and recent advances in symbolic regression techniques. Next, the authors discuss industrial applications of symbolic regression and its potential applications in materials science. The authors then present two GPSR use-cases: formulating a transformation kinetics law and showing the learning scheme discovers the well-known Johnson–Mehl–Avrami–Kolmogorov form, and learning the Landau free energy functional form for the displacive tilt transition in perovskite LaNiO3. Finally, the authors propose that symbolic regression techniques should be considered by materials scientists as an alternative to other machine learning-based regression models for learning from data.
%G en
%J MRS Communications
%A Wang, Yiqun
%A Wagner, Nicholas
%A Rondinelli, James M.
%D 09/2019

%0 Journal Article
%T Discovering Mathematical Expressions Through DeepSymNet: A Classification-Based Symbolic Regression Framework
%P 1-15
%* https://creativecommons.org/licenses/by-nc-nd/4.0/
%U https://ieeexplore.ieee.org/document/10327762/
%X Symbolic regression (SR) is the process of finding an unknown mathematical expression given the input and output and has important applications in interpretable machine learning and knowledge discovery. The major difficulty of SR is that finding the expression structure is an NP-hard problem, which makes the entire process time-consuming. In this study, the solution of expression structures was regarded as a classification problem and solved by supervised learning such that SR can be solved quickly by using the solving experience. Techniques for classification tasks, such as equivalent label merging and sample balance, were used to enhance the robustness of the algorithm. We proposed a symbolic network called DeepSymNet to represent symbolic expressions to improve the performance of the algorithm. DeepSymNet has been proven to have a strong representation ability with a shorter label compared to the current popular representation methods, reducing the search space when predicting. Moreover, DeepSymNet conveniently decomposes SR into two smaller subproblems, which makes solving the problem easier. The proposed algorithm was tested on artificially generated expressions and public datasets and compared with other algorithms. The results demonstrate the effectiveness of the proposed algorithm.
%G en
%J IEEE Transactions on Neural Networks and Learning Systems
%A Wu, Min
%A Li, Weijun
%A Yu, Lina
%A Sun, Linjun
%A Liu, Jingyi
%A Li, Wenqiang
%D 2024

%0 Conference Paper
%T DEEP SYMBOLIC REGRESSION: RECOVERING MATHEMATICAL EXPRESSIONS FROM DATA VIA RISK-SEEKING POLICY GRADIENTS
%X Discovering the underlying mathematical expressions describing a dataset is a core challenge for artiﬁcial intelligence. This is the problem of symbolic regression. Despite recent advances in training neural networks to solve complex tasks, deep learning approaches to symbolic regression are underexplored. We propose a framework that leverages deep learning for symbolic regression via a simple idea: use a large model to search the space of small models. Speciﬁcally, we use a recurrent neural network to emit a distribution over tractable mathematical expressions and employ a novel risk-seeking policy gradient to train the network to generate better-ﬁtting expressions. Our algorithm outperforms several baseline methods (including Eureqa, the gold standard for symbolic regression) in its ability to exactly recover symbolic expressions on a series of benchmark problems, both with and without added noise. More broadly, our contributions include a framework that can be applied to optimize hierarchical, variable-length objects under a blackbox performance metric, with the ability to incorporate constraints in situ, and a risk-seeking policy gradient formulation that optimizes for best-case performance instead of expected performance.
%G en
%B ICLR 2021
%A Petersen, Brenden K
%A Larma, Mikel Landajuela
%A Mundhenk, T Nathan
%A Santiago, Claudio P
%A Kim, Soo K
%A Kim, Joanne T
%D 2021
%K Computer Science - Machine Learning
Statistics - Machine Learning

%0 Conference Paper
%T Deep Generative Symbolic Regression
%I arXiv
%U http://arxiv.org/abs/2401.00282
%X Symbolic regression (SR) aims to discover concise closed-form mathematical equations from data, a task fundamental to scientific discovery. However, the problem is highly challenging because closed-form equations lie in a complex combinatorial search space. Existing methods, ranging from heuristic search to reinforcement learning, fail to scale with the number of input variables. We make the observation that closed-form equations often have structural characteristics and invariances (e.g., the commutative law) that could be further exploited to build more effective symbolic regression solutions. Motivated by this observation, our key contribution is to leverage pre-trained deep generative models to capture the intrinsic regularities of equations, thereby providing a solid foundation for subsequent optimization steps. We show that our novel formalism unifies several prominent approaches of symbolic regression and offers a new perspective to justify and improve on the previous ad hoc designs, such as the usage of cross-entropy loss during pre-training. Specifically, we propose an instantiation of our framework, Deep Generative Symbolic Regression (DGSR). In our experiments, we show that DGSR achieves a higher recovery rate of true equations in the setting of a larger number of input variables, and it is more computationally efficient at inference time than state-of-the-art RL symbolic regression solutions.
%G en
%B ICLR 2023
%A Holt, Samuel
%A Qian, Zhaozhi
%A Schaar, Mihaela van der
%D 2023-12-30
%K Computer Science - Machine Learning

%0 Journal Article
%T Interpretable machine learning for science with PySR and SymbolicRegression. jl
%J arXiv preprint arXiv:2305.01582
%A Cranmer, Miles
%D 2023

%0 Journal Article
%T Physics-informed learning of governing equations from scarce data
%V 12
%N 1
%P 6136
%U https://www.nature.com/articles/s41467-021-26434-1
%X Abstract
            Harnessing data to discover the underlying governing laws or equations that describe the behavior of complex physical systems can significantly advance our modeling, simulation and understanding of such systems in various science and engineering disciplines. This work introduces a novel approach called physics-informed neural network with sparse regression to discover governing partial differential equations from scarce and noisy data for nonlinear spatiotemporal systems. In particular, this discovery approach seamlessly integrates the strengths of deep neural networks for rich representation learning, physics embedding, automatic differentiation and sparse regression to approximate the solution of system variables, compute essential derivatives, as well as identify the key derivative terms and parameters that form the structure and explicit expression of the equations. The efficacy and robustness of this method are demonstrated, both numerically and experimentally, on discovering a variety of partial differential equation systems with different levels of data scarcity and noise accounting for different initial/boundary conditions. The resulting computational framework shows the potential for closed-form model discovery in practical applications where large and accurate datasets are intractable to capture.
%G en
%J Nature Communications
%A Chen, Zhao
%A Liu, Yang
%A Sun, Hao
%D 2021-10-21

%0 Generic
%T Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks
%I arXiv
%U http://arxiv.org/abs/1810.00825
%X Many machine learning tasks such as multiple instance learning, 3D shape recognition and fewshot image classiﬁcation are deﬁned on sets of instances. Since solutions to such problems do not depend on the order of elements of the set, models used to address them should be permutation invariant. We present an attention-based neural network module, the Set Transformer, speciﬁcally designed to model interactions among elements in the input set. The model consists of an encoder and a decoder, both of which rely on attention mechanisms. In an effort to reduce computational complexity, we introduce an attention scheme inspired by inducing point methods from sparse Gaussian process literature. It reduces computation time of self-attention from quadratic to linear in the number of elements in the set. We show that our model is theoretically attractive and we evaluate it on a range of tasks, demonstrating increased performance compared to recent methods for set-structured data.
%G en
%A Lee, Juho
%A Lee, Yoonho
%A Kim, Jungtaek
%A Kosiorek, Adam R.
%A Choi, Seungjin
%A Teh, Yee Whye
%D 2019-05-26
%K Computer Science - Machine Learning
Statistics - Machine Learning

%0 Generic
%T Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
%I arXiv
%U http://arxiv.org/abs/1910.10683
%X Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new ``Colossal Clean Crawled Corpus'', we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.
%G en
%A Raffel, Colin
%A Shazeer, Noam
%A Roberts, Adam
%A Lee, Katherine
%A Narang, Sharan
%A Matena, Michael
%A Zhou, Yanqi
%A Li, Wei
%A Liu, Peter J.
%D 2023-09-19
%K Computer Science - Computation and Language
Computer Science - Machine Learning
Statistics - Machine Learning

%0 Generic
%T Neural Symbolic Regression that Scales
%I arXiv
%U http://arxiv.org/abs/2106.06427
%X Symbolic equations are at the core of scientiﬁc discovery. The task of discovering the underlying equation from a set of input-output pairs is called symbolic regression. Traditionally, symbolic regression methods use hand-designed strategies that do not improve with experience. In this paper, we introduce the ﬁrst symbolic regression method that leverages large scale pre-training. We procedurally generate an unbounded set of equations, and simultaneously pre-train a Transformer to predict the symbolic equation from a corresponding set of input-output-pairs. At test time, we query the model on a new set of points and use its output to guide the search for the equation. We show empirically that this approach can re-discover a set of well-known physical equations, and that it improves over time with more data and compute.
%G en
%A Biggio, Luca
%A Bendinelli, Tommaso
%A Neitz, Alexander
%A Lucchi, Aurelien
%A Parascandolo, Giambattista
%D 2021-06-11
%K Computer Science - Machine Learning

%0 Generic
%T SymbolicGPT: A Generative Transformer Model for Symbolic Regression
%I arXiv
%U http://arxiv.org/abs/2106.14131
%X Symbolic regression is the task of identifying a mathematical expression that best ﬁts a provided dataset of input and output values. Due to the richness of the space of mathematical expressions, symbolic regression is generally a challenging problem. While conventional approaches based on genetic evolution algorithms have been used for decades, deep learning-based methods are relatively new and an active research area. In this work, we present SymbolicGPT, a novel transformer-based language model for symbolic regression3. This model exploits the advantages of probabilistic language models like GPT, including strength in performance and ﬂexibility. Through comprehensive experiments, we show that our model performs strongly compared to competing models with respect to the accuracy, running time, and data efﬁciency.
%G en
%A Valipour, Mojtaba
%A You, Bowen
%A Panju, Maysum
%A Ghodsi, Ali
%D 2021-06-27
%K Computer Science - Computation and Language
Computer Science - Machine Learning
Computer Science - Symbolic Computation

%0 Journal Article
%T Deep Symbolic Regression for Physics Guided by Units Constraints: Toward the Automated Discovery of Physical Laws
%V 959
%N 2
%P 99
%U https://iopscience.iop.org/article/10.3847/1538-4357/ad014c
%X Symbolic regression (SR) is the study of algorithms that automate the search for analytic expressions that ﬁt data. While recent advances in deep learning have generated renewed interest in such approaches, the development of SR methods has not been focused on physics, where we have important additional constraints due to the units associated with our data. Here we present Φ-SO, a physical symbolic optimization framework for recovering analytical symbolic expressions from physics data using deep reinforcement learning techniques by learning units constraints. Our system is built, from the ground up, to propose solutions where the physical units are consistent by construction. This is useful not only in eliminating physically impossible solutions but also because the grammatical rules of dimensional analysis enormously restrict the freedom of the equation generator, thus vastly improving performance. The algorithm can be used to ﬁt noiseless data, which can be useful, for instance, when attempting to derive an analytical property of a physical model, and it can also be used to obtain analytical approximations of noisy data. We test our machinery on a standard benchmark of equations from the Feynman Lectures on Physics and other physics textbooks, achieving state-of-the-art performance in the presence of noise (exceeding 0.1%) and show that it is robust even in the presence of substantial (10%) noise. We showcase its abilities on a panel of examples from astrophysics.
%G en
%J The Astrophysical Journal
%A Tenachi, Wassim
%A Ibata, Rodrigo
%A Diakogiannis, Foivos I.
%D 2023-12-01

%0 Journal Article
%T SRBench++: Principled Benchmarking of Symbolic Regression With Domain-Expert Interpretation
%P 1-1
%* https://creativecommons.org/licenses/by/4.0/legalcode
%U https://ieeexplore.ieee.org/document/10586218/
%X Symbolic regression searches for analytic expressions that accurately describe studied phenomena. The main promise of this approach is that it may return an interpretable model that can be insightful to users, while maintaining high accuracy. The current standard for benchmarking these algorithms is SRBench, which evaluates methods on hundreds of datasets that are a mix of real-world and simulated processes spanning multiple domains. At present, the ability of SRBench to evaluate interpretability is limited to measuring the size of expressions on real-world data, and the exactness of model forms on synthetic data. In practice, model size is only one of many factors used by subject experts to determine how interpretable a model truly is. Furthermore, SRBench does not characterize algorithm performance on speciﬁc, challenging sub-tasks of regression such as feature selection and evasion of local minima. In this work, we propose and evaluate an approach to benchmarking SR algorithms that addresses these limitations of SRBench by 1) incorporating expert evaluations of interpretability on a domain-speciﬁc task, and 2) evaluating algorithms over distinct properties of data science tasks. We evaluate 12 modern symbolic regression algorithms on these benchmarks and present an in-depth analysis of the results, discuss current challenges of symbolic regression algorithms and highlight possible improvements for the benchmark itself.
%G en
%J IEEE Transactions on Evolutionary Computation
%A De Franca, F. O.
%A Virgolin, M.
%A Kommenda, M.
%A Majumder, M. S.
%A Cranmer, M.
%A Espada, G.
%A Ingelse, L.
%A Fonseca, A.
%A Landajuela, M.
%A Petersen, B.
%A Glatt, R.
%A Mundhenk, N.
%A Lee, C. S.
%A Hochhalter, J. D.
%A Randall, D. L.
%A Kamienny, P.
%A Zhang, H.
%A Dick, G.
%A Simon, A.
%A Burlacu, B.
%A Kasak, Jaan
%A Machado, Meera
%A Wilstrup, Casper
%A Cavaz, W. G. La
%D 2024

%0 Journal Article
%T Defected elastic metasurfaces for structured focusing with the extension of Babinet principle
%V 78
%P 102366
%U https://linkinghub.elsevier.com/retrieve/pii/S2352431625000781
%X Defects offer a new geometric freedom in metamaterials or phononic crystals to functionally modulate waves, but remain unexplored in a low-dimensional version of artificial structures. We here introduce the concept of a defected metasurface that enables structured focusing by breaking the traditional design notion of perfect metasurfaces for single focus. We theoretically and experimentally demonstrate that the distance between focal points is smaller than the wavelength, which is a challenging task previously. Moreover, the number and the energy distribution of foci can be tailored via integrating defects with the metasurface, which can be well described based on the Babinet principle. We further realize the Talbot effect to generate periodically focusing and digital coding. This defected prototype offers a promising strategy to shape structured elastic waves for nondestructive testing, and may be extended to other fields on the design of efficient acoustic or optical tweezer arrays.
%G en
%J Extreme Mechanics Letters
%A Shi, Yun
%A Cheng, Jiali
%A Su, Guangyuan
%A Zhao, Meiying
%A Liu, Yongquan
%A Li, Bing
%D 08/2025

%0 Journal Article
%T Interpretable scientific discovery with symbolic regression: a review
%V 57
%N 1
%P 2
%U https://link.springer.com/10.1007/s10462-023-10622-0
%X Symbolic regression is emerging as a promising machine learning method for learning succinct underlying interpretable mathematical expressions directly from data. Whereas it has been traditionally tackled with genetic programming, it has recently gained a growing interest in deep learning as a data-driven model discovery tool, achieving significant advances in various application domains ranging from fundamental to applied sciences. In this survey, we present a structured and comprehensive overview of symbolic regression methods, review the adoption of these methods for model discovery in various areas, and assess their effectiveness. We have also grouped state-of-the-art symbolic regression applications in a categorized manner in a living review.
%G en
%J Artificial Intelligence Review
%A Makke, Nour
%A Chawla, Sanjay
%D 01/2024

%0 Journal Article
%T Artificial Intelligence in Physical Sciences: Symbolic Regression Trends and Perspectives
%V 30
%N 6
%P 3845-3865
%U https://link.springer.com/10.1007/s11831-023-09922-z
%X Symbolic regression (SR) is a machine learning-based regression method based on genetic programming principles that integrates techniques and processes from heterogeneous scientific fields and is capable of providing analytical equations purely from data. This remarkable characteristic diminishes the need to incorporate prior knowledge about the investigated system. SR can spot profound and elucidate ambiguous relations that can be generalizable, applicable, explainable and span over most scientific, technological, economical, and social principles. In this review, current state of the art is documented, technical and physical characteristics of SR are presented, the available programming techniques are investigated, fields of application are explored, and future perspectives are discussed.
%G en
%J Archives of Computational Methods in Engineering
%A Angelis, Dimitrios
%A Sofos, Filippos
%A Karakasidis, Theodoros E.
%D 07/2023

